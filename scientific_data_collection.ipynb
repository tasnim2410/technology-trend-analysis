{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**semantic scolar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 20394087, 'offset': 0, 'next': 5, 'data': [{'paperId': '13a0d8bb38f739990c8cd65a44061c6534f17221', 'title': 'OPT: Open Pre-trained Transformer Language Models', 'abstract': 'Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.', 'year': 2022, 'citationCount': 3306, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2205.01068, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2108244542', 'name': 'Susan Zhang'}, {'authorId': '3849208', 'name': 'Stephen Roller'}, {'authorId': '39589154', 'name': 'Naman Goyal'}, {'authorId': '2347956', 'name': 'Mikel Artetxe'}, {'authorId': '2108267192', 'name': 'Moya Chen'}, {'authorId': '1782969', 'name': 'Shuohui Chen'}, {'authorId': '2065332326', 'name': 'Christopher Dewan'}, {'authorId': '2138579860', 'name': 'Mona T. Diab'}, {'authorId': '2116235416', 'name': 'Xian Li'}, {'authorId': '143724481', 'name': 'Xi Victoria Lin'}, {'authorId': '39980906', 'name': 'Todor Mihaylov'}, {'authorId': '40511414', 'name': 'Myle Ott'}, {'authorId': '88728159', 'name': 'Sam Shleifer'}, {'authorId': '35752280', 'name': 'Kurt Shuster'}, {'authorId': '2082239112', 'name': 'Daniel Simig'}, {'authorId': '2146367061', 'name': 'Punit Singh Koura'}, {'authorId': '5382923', 'name': 'Anjali Sridhar'}, {'authorId': '1785372925', 'name': 'Tianlu Wang'}, {'authorId': '1982950', 'name': 'Luke Zettlemoyer'}]}, {'paperId': '5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200', 'title': 'GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints', 'abstract': 'Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference. We (1) propose a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) introduce grouped-query attention (GQA), a generalization of multi-query attention which uses an intermediate (more than one, less than number of query heads) number of key-value heads. We show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.', 'year': 2023, 'citationCount': 496, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2305.13245', 'status': 'CLOSED', 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2305.13245, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '1643737606', 'name': 'J. Ainslie'}, {'authorId': '1405626394', 'name': 'J. Lee-Thorp'}, {'authorId': '21379393', 'name': 'Michiel de Jong'}, {'authorId': '51199981', 'name': 'Yury Zemlyanskiy'}, {'authorId': '2218311992', 'name': \"Federico Lebr'on\"}, {'authorId': '144074891', 'name': 'Sumit K. Sanghai'}]}, {'paperId': 'f09fb94199290b4638a91750540bbbed4e4420b1', 'title': 'Integrating prior knowledge to build transformer models', 'abstract': 'The big Artificial General Intelligence models inspire hot topics currently. The black box problems of Artificial Intelligence (AI) models still exist and need to be solved urgently, especially in the medical area. Therefore, transparent and reliable AI models with small data are also urgently necessary. To build a trustable AI model with small data, we proposed a prior knowledge-integrated transformer model. We first acquired prior knowledge using Shapley Additive exPlanations from various pre-trained machine learning models. Then, we used the prior knowledge to construct the transformer models and compared our proposed models with the Feature Tokenization Transformer model and other classification models. We tested our proposed model on three open datasets and one non-open public dataset in Japan to confirm the feasibility of our proposed methodology. Our results certified that knowledge-integrated transformer models perform better (1%) than general transformer models. Meanwhile, our proposed methodology identified that the self-attention of factors in our proposed transformer models is nearly the same, which needs to be explored in future work. Moreover, our research inspires future endeavors in exploring transparent small AI models.', 'year': 2024, 'citationCount': 22, 'openAccessPdf': {'url': 'https://link.springer.com/content/pdf/10.1007/s41870-023-01635-7.pdf', 'status': 'HYBRID', 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://api.unpaywall.org/v2/10.1007/s41870-023-01635-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s41870-023-01635-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2277881594', 'name': 'Pei Jiang'}, {'authorId': '2277875587', 'name': 'Takashi Obi'}, {'authorId': '2277881566', 'name': 'Yoshikazu Nakajima'}]}, {'paperId': '815bf0a659f3363fbf8f51632b58f29bcb699491', 'title': 'Transformer Models in Healthcare: A Survey and Thematic Analysis of Potentials, Shortcomings and Risks', 'abstract': 'Large Language Models (LLMs) such as General Pretrained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT), which use transformer model architectures, have significantly advanced artificial intelligence and natural language processing. Recognized for their ability to capture associative relationships between words based on shared context, these models are poised to transform healthcare by improving diagnostic accuracy, tailoring treatment plans, and predicting patient outcomes. However, there are multiple risks and potentially unintended consequences associated with their use in healthcare applications. This study, conducted with 28 participants using a qualitative approach, explores the benefits, shortcomings, and risks of using transformer models in healthcare. It analyses responses to seven open-ended questions using a simplified thematic analysis. Our research reveals seven benefits, including improved operational efficiency, optimized processes and refined clinical documentation. Despite these benefits, there are significant concerns about the introduction of bias, auditability issues and privacy risks. Challenges include the need for specialized expertise, the emergence of ethical dilemmas and the potential reduction in the human element of patient care. For the medical profession, risks include the impact on employment, changes in the patient-doctor dynamic, and the need for extensive training in both system operation and data interpretation.', 'year': 2024, 'citationCount': 22, 'openAccessPdf': {'url': '', 'status': None, 'license': 'CCBY', 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC10874304, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2261266738', 'name': 'Kerstin Denecke'}, {'authorId': '2055463465', 'name': 'R. May'}, {'authorId': '2265246980', 'name': 'Octavio Rivera'}]}, {'paperId': '7b248d78573ccf0dca6aa2cec2743d3eccaa9d1a', 'title': 'CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer', 'abstract': 'We present CogVideoX, a large-scale text-to-video generation model based on diffusion transformer, which can generate 10-second continuous videos aligned with text prompt, with a frame rate of 16 fps and resolution of 768 * 1360 pixels. Previous video generation models often had limited movement and short durations, and is difficult to generate videos with coherent narratives based on text. We propose several designs to address these issues. First, we propose a 3D Variational Autoencoder (VAE) to compress videos along both spatial and temporal dimensions, to improve both compression rate and video fidelity. Second, to improve the text-video alignment, we propose an expert transformer with the expert adaptive LayerNorm to facilitate the deep fusion between the two modalities. Third, by employing a progressive training and multi-resolution frame pack technique, CogVideoX is adept at producing coherent, long-duration, different shape videos characterized by significant motions. In addition, we develop an effective text-video data processing pipeline that includes various data preprocessing strategies and a video captioning method, greatly contributing to the generation quality and semantic alignment. Results show that CogVideoX demonstrates state-of-the-art performance across both multiple machine metrics and human evaluations. The model weight of both 3D Causal VAE, Video caption model and CogVideoX are publicly available at https://github.com/THUDM/CogVideo.', 'year': 2024, 'citationCount': 305, 'openAccessPdf': {'url': '', 'status': None, 'license': None, 'disclaimer': 'Notice: This abstract is extracted from the open access paper or abstract available at https://arxiv.org/abs/2408.06072, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use.'}, 'authors': [{'authorId': '2303231681', 'name': 'Zhuoyi Yang'}, {'authorId': '2238205354', 'name': 'Jiayan Teng'}, {'authorId': '2163967642', 'name': 'Wendi Zheng'}, {'authorId': '2055623340', 'name': 'Ming Ding'}, {'authorId': '2305795673', 'name': 'Shiyu Huang'}, {'authorId': '2214082934', 'name': 'Jiazheng Xu'}, {'authorId': '2315948290', 'name': 'Yuanming Yang'}, {'authorId': '2105844599', 'name': 'Wenyi Hong'}, {'authorId': '2268628279', 'name': 'Xiaohan Zhang'}, {'authorId': '2307077651', 'name': 'Guanyu Feng'}, {'authorId': '2307075814', 'name': 'Da Yin'}, {'authorId': '2290625851', 'name': 'Xiaotao Gu'}, {'authorId': '2316099643', 'name': 'Yuxuan Zhang'}, {'authorId': '2265518149', 'name': 'Weihan Wang'}, {'authorId': '2306161782', 'name': 'Yean Cheng'}, {'authorId': '2315952736', 'name': 'Ting Liu'}, {'authorId': '2288066971', 'name': 'Bin Xu'}, {'authorId': '2243402027', 'name': 'Yuxiao Dong'}, {'authorId': '2238207092', 'name': 'Jie Tang'}]}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "# Basic search parameters\n",
    "url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "params = {\n",
    "    'query': 'transformer models',\n",
    "    'fields': 'title,authors,year,citationCount,abstract',\n",
    "    'limit': 5\n",
    "}\n",
    "\n",
    "# headers = {\n",
    "#     'x-api-key': 'YOUR_API_KEY'  # if you have one (optional but recommended)\n",
    "# }\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         Title  \\\n",
      "0            OPT: Open Pre-trained Transformer Language Models   \n",
      "1  GQA: Training Generalized Multi-Query Transformer Models...   \n",
      "2      Integrating prior knowledge to build transformer models   \n",
      "3  Transformer Models in Healthcare: A Survey and Thematic ...   \n",
      "4  CogVideoX: Text-to-Video Diffusion Models with An Expert...   \n",
      "\n",
      "                                                       Authors  Year  \\\n",
      "0  Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe,...  2022   \n",
      "1  J. Ainslie, J. Lee-Thorp, Michiel de Jong, Yury Zemlyans...  2023   \n",
      "2                   Pei Jiang, Takashi Obi, Yoshikazu Nakajima  2024   \n",
      "3                      Kerstin Denecke, R. May, Octavio Rivera  2024   \n",
      "4  Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu ...  2024   \n",
      "\n",
      "   Citations                                                     Abstract  \n",
      "0       3306  Large language models, which are often trained for hundr...  \n",
      "1        496  Multi-query attention (MQA), which only uses a single ke...  \n",
      "2         22  The big Artificial General Intelligence models inspire h...  \n",
      "3         22  Large Language Models (LLMs) such as General Pretrained ...  \n",
      "4        305  We present CogVideoX, a large-scale text-to-video genera...  \n"
     ]
    }
   ],
   "source": [
    "# Process the results into a DataFrame\n",
    "if 'data' in data:\n",
    "    formatted_data = []\n",
    "    for paper in data['data']:\n",
    "        formatted_paper = {\n",
    "            'Title': paper.get('title'),\n",
    "            'Authors': ', '.join([author['name'] for author in paper.get('authors', [])]),\n",
    "            'Year': paper.get('year'),\n",
    "            'Citations': paper.get('citationCount'),\n",
    "            'Abstract': paper.get('abstract')[:300] + '...' if paper.get('abstract') else None\n",
    "        }\n",
    "        formatted_data.append(formatted_paper)\n",
    "    \n",
    "    df = pd.DataFrame(formatted_data)\n",
    "    pd.set_option('display.max_colwidth', 60)  # Adjust column width\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No results found or API error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found or API error\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# API details\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "api_key = \"Qeg1buThqizr68MqzRKFLpEN\"\n",
    "query = \"Langchain\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Loop through pages 1 to 50\n",
    "for page in range(1, 51):\n",
    "    params = {\n",
    "        \"engine\": \"google_scholar\",\n",
    "        \"q\": query,\n",
    "        \"api_key\": api_key,\n",
    "        \"num\": 20,\n",
    "        \"page\": page\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error on page {page}: {response.status_code}\")\n",
    "        continue\n",
    "    \n",
    "    data = response.json()\n",
    "    organic_results = data.get(\"organic_results\", [])\n",
    "    all_results.extend(organic_results)\n",
    "    \n",
    "    time.sleep(1)  # polite delay, can reduce or remove if needed\n",
    "\n",
    "# Save all results as JSON\n",
    "# with open(\"langchain_results.json\", \"w\", encoding='utf-8') as f:\n",
    "#     json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# print(f\"Saved {len(all_results)} results to langchain_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>RelativeDate</th>\n",
       "      <th>FormattedDate</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...</td>\n",
       "      <td>Times of India</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>2025-04-07 03:14</td>\n",
       "      <td>TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Post Opinions section anxiously awaits new le...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>2025-04-04 15:14</td>\n",
       "      <td>The Washington Post has faced an exodus of talent in rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What to know about Bezos Academy, the Jeff Bezos prescho...</td>\n",
       "      <td>The Arizona Republic</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>2025-04-06 15:14</td>\n",
       "      <td>Bezos Academy will open in Glendale in September and off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Under Trump and Musk, billionaires wield unprecedented i...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>2025-04-06 18:14</td>\n",
       "      <td>Government officials and contractors long controlled spy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacKenzie Scott Has Given Away $19 Billion Since Divorce...</td>\n",
       "      <td>People.com</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>2025-04-07 01:14</td>\n",
       "      <td>MacKenzie Scott has \"transformed\" philanthropy since her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title  \\\n",
       "0  Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...   \n",
       "1  Washington Post Opinions section anxiously awaits new le...   \n",
       "2  What to know about Bezos Academy, the Jeff Bezos prescho...   \n",
       "3  Under Trump and Musk, billionaires wield unprecedented i...   \n",
       "4  MacKenzie Scott Has Given Away $19 Billion Since Divorce...   \n",
       "\n",
       "                 Source  RelativeDate     FormattedDate  \\\n",
       "0        Times of India  12 hours ago  2025-04-07 03:14   \n",
       "1              Fox News    3 days ago  2025-04-04 15:14   \n",
       "2  The Arizona Republic     1 day ago  2025-04-06 15:14   \n",
       "3          The Guardian  21 hours ago  2025-04-06 18:14   \n",
       "4            People.com  14 hours ago  2025-04-07 01:14   \n",
       "\n",
       "                                                       Snippet  \n",
       "0  TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...  \n",
       "1  The Washington Post has faced an exodus of talent in rec...  \n",
       "2  Bezos Academy will open in Glendale in September and off...  \n",
       "3  Government officials and contractors long controlled spy...  \n",
       "4  MacKenzie Scott has \"transformed\" philanthropy since her...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "params = {\n",
    "    \"engine\": \"google_news\",\n",
    "    \"q\": \"Jeff Bezos news\",\n",
    "    \"location\": \"New York,United States\",\n",
    "    \"api_key\": \"Qeg1buThqizr68MqzRKFLpEN\"\n",
    "}\n",
    "\n",
    "# Fetch data from API\n",
    "response = requests.get(url, params=params)\n",
    "news_data = response.json()\n",
    "\n",
    "# Process news results\n",
    "news_results = news_data.get(\"organic_results\", [])\n",
    "\n",
    "def parse_relative_date(date_str):\n",
    "    \"\"\"Convert relative date strings to datetime objects\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        # Parse relative date (e.g., \"1 day ago\")\n",
    "        parsed_date = dateparser.parse(date_str)\n",
    "        \n",
    "        # For dates without year information, ensure we don't default to 2000\n",
    "        if parsed_date and parsed_date.year == 2000:\n",
    "            current_year = datetime.now().year\n",
    "            parsed_date = parsed_date.replace(year=current_year)\n",
    "            \n",
    "        return parsed_date\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "records = []\n",
    "for item in news_results:\n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        \"Source\": item.get(\"source\"),\n",
    "        \"RelativeDate\": item.get(\"date\"),  # Original string (e.g., \"1 day ago\")\n",
    "        \"Date\": parse_relative_date(item.get(\"date\")),  # Parsed datetime\n",
    "        \"Snippet\": item.get(\"snippet\"),\n",
    "        \"Link\": item.get(\"link\"),\n",
    "        \"HasThumbnail\": bool(item.get(\"thumbnail\")),\n",
    "        \"Position\": item.get(\"position\")\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Format the datetime for display\n",
    "df['FormattedDate'] = df['Date'].dt.strftime('%Y-%m-%d %H:%M') if not df.empty else None\n",
    "\n",
    "# Show results\n",
    "df[['Title', 'Source', 'RelativeDate', 'FormattedDate', 'Snippet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>RelativeDate</th>\n",
       "      <th>FormattedDate</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...</td>\n",
       "      <td>Times of India</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>2025-04-07 03:14</td>\n",
       "      <td>TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Post Opinions section anxiously awaits new le...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>2025-04-04 15:14</td>\n",
       "      <td>The Washington Post has faced an exodus of talent in rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What to know about Bezos Academy, the Jeff Bezos prescho...</td>\n",
       "      <td>The Arizona Republic</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>2025-04-06 15:14</td>\n",
       "      <td>Bezos Academy will open in Glendale in September and off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Under Trump and Musk, billionaires wield unprecedented i...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>2025-04-06 18:14</td>\n",
       "      <td>Government officials and contractors long controlled spy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacKenzie Scott Has Given Away $19 Billion Since Divorce...</td>\n",
       "      <td>People.com</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>2025-04-07 01:14</td>\n",
       "      <td>MacKenzie Scott has \"transformed\" philanthropy since her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title  \\\n",
       "0  Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...   \n",
       "1  Washington Post Opinions section anxiously awaits new le...   \n",
       "2  What to know about Bezos Academy, the Jeff Bezos prescho...   \n",
       "3  Under Trump and Musk, billionaires wield unprecedented i...   \n",
       "4  MacKenzie Scott Has Given Away $19 Billion Since Divorce...   \n",
       "\n",
       "                 Source  RelativeDate     FormattedDate  \\\n",
       "0        Times of India  12 hours ago  2025-04-07 03:14   \n",
       "1              Fox News    3 days ago  2025-04-04 15:14   \n",
       "2  The Arizona Republic     1 day ago  2025-04-06 15:14   \n",
       "3          The Guardian  21 hours ago  2025-04-06 18:14   \n",
       "4            People.com  14 hours ago  2025-04-07 01:14   \n",
       "\n",
       "                                                       Snippet  \n",
       "0  TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...  \n",
       "1  The Washington Post has faced an exodus of talent in rec...  \n",
       "2  Bezos Academy will open in Glendale in September and off...  \n",
       "3  Government officials and contractors long controlled spy...  \n",
       "4  MacKenzie Scott has \"transformed\" philanthropy since her...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "params = {\n",
    "    \"engine\": \"google_news\",\n",
    "    \"q\": \"Jeff Bezos news\",\n",
    "    \"location\": \"New York,United States\",\n",
    "    \"api_key\": \"Qeg1buThqizr68MqzRKFLpEN\"\n",
    "}\n",
    "\n",
    "# Fetch data from API\n",
    "response = requests.get(url, params=params)\n",
    "news_data = response.json()\n",
    "\n",
    "# Process news results\n",
    "news_results = news_data.get(\"organic_results\", [])\n",
    "\n",
    "def parse_relative_date(date_str):\n",
    "    \"\"\"Convert relative date strings to datetime objects\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        # Parse relative date (e.g., \"1 day ago\")\n",
    "        parsed_date = dateparser.parse(date_str)\n",
    "        \n",
    "        # For dates without year information, ensure we don't default to 2000\n",
    "        if parsed_date and parsed_date.year == 2000:\n",
    "            current_year = datetime.now().year\n",
    "            parsed_date = parsed_date.replace(year=current_year)\n",
    "            \n",
    "        return parsed_date\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "records = []\n",
    "for item in news_results:\n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        \"Source\": item.get(\"source\"),\n",
    "        \"RelativeDate\": item.get(\"date\"),  # Original string (e.g., \"1 day ago\")\n",
    "        \"Date\": parse_relative_date(item.get(\"date\")),  # Parsed datetime\n",
    "        \"Snippet\": item.get(\"snippet\"),\n",
    "        \"Link\": item.get(\"link\"),\n",
    "        \"HasThumbnail\": bool(item.get(\"thumbnail\")),\n",
    "        \"Position\": item.get(\"position\")\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Format the datetime for display\n",
    "df['FormattedDate'] = df['Date'].dt.strftime('%Y-%m-%d %H:%M') if not df.empty else None\n",
    "\n",
    "# Show results\n",
    "df[['Title', 'Source', 'RelativeDate', 'FormattedDate', 'Snippet']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**google patents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['search_metadata', 'search_parameters', 'search_information', 'organic_results', 'summary', 'pagination'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "params = {\n",
    "    \"engine\": \"google_patents\",\n",
    "    \"q\": \"technology trend monitoring\",\n",
    "    \"api_key\": \"Qeg1buThqizr68MqzRKFLpEN\"  # Replace with your key\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://www.searchapi.io/api/v1/search\", params=params)\n",
    "gpdata = response.json()\n",
    "gpdata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['position', 'rank', 'patent_id', 'title', 'snippet', 'priority_date', 'filing_date', 'grant_date', 'publication_date', 'inventor', 'assignee', 'publication_number', 'language', 'pdf', 'country_status'])\n"
     ]
    }
   ],
   "source": [
    "if 'organic_results' in gpdata and gpdata['organic_results'] : \n",
    "  print(gpdata['organic_results'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**google scolar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 500 results across 50 pages.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time  # in case we want to be polite and add delays\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "api_key = \"BdVJ9kUYpdfAw6RYXy1t6KQm\"\n",
    "\n",
    "# Parameters\n",
    "query = \"Langchain\"\n",
    "results = []\n",
    "\n",
    "# Loop through first 50 pages\n",
    "for page in range(1, 21):  # Pages 1 to 50\n",
    "    params = {\n",
    "        \"engine\": \"google_scholar\",\n",
    "        \"q\": query,\n",
    "        \"api_key\": api_key,\n",
    "        \"num\": 20,         # max per page\n",
    "        \"page\": page\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed on page {page}: {response.status_code}\")\n",
    "        continue\n",
    "\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract and add the organic results\n",
    "    organic_results = data.get(\"organic_results\", [])\n",
    "    results.extend(organic_results)\n",
    "    \n",
    "    # Optional: Be polite to the API (1-second delay)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "gsc_data = pd.DataFrame(results)\n",
    "\n",
    "# Export to Excel\n",
    "#df.to_excel(\"langchain_scholar_results.xlsx\", index=False)\n",
    "\n",
    "print(f\"Scraped {len(results)} results across 50 pages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 0 results across 5 pages.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time  # in case we want to be polite and add delays\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "api_key = \"BdVJ9kUYpdfAw6RYXy1t6KQm\"\n",
    "\n",
    "# Parameters\n",
    "query = \"Langchain\"\n",
    "results = []\n",
    "\n",
    "# Loop through first 50 pages\n",
    "for page in range(1, 6):  # Pages 1 to 50\n",
    "    params = {\n",
    "        \"engine\": \"google_scholar\",\n",
    "        \"q\": query,\n",
    "        \"api_key\": api_key,\n",
    "        \"num\": 30,         # max per page\n",
    "        \"page\": page\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed on page {page}: {response.status_code}\")\n",
    "        continue\n",
    "\n",
    "    gsc_data = response.json()\n",
    "    gsc_data.keys()\n",
    "  \n",
    "\n",
    "print(f\"Scraped {len(gsc_data)} results across 5 pages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsc_data.to_excel('google_scolar_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['position', 'title', 'data_cid', 'link', 'publication', 'snippet', 'inline_links'])\n"
     ]
    }
   ],
   "source": [
    "if 'organic_results' in gsc_data and gsc_data['organic_results'] : \n",
    "  print(gsc_data['organic_results'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: Type -> <class 'int'>, Sample -> 2\n",
      "title: Type -> <class 'str'>, Sample -> Automated Generation and Evaluation of MultipleChoice Quizzes using Langchain and Gemini LLM\n",
      "data_cid: Type -> <class 'str'>, Sample -> Qduivk7Vf4gJ\n",
      "link: Type -> <class 'str'>, Sample -> https://ieeexplore.ieee.org/abstract/document/10739326/\n",
      "publication: Type -> <class 'str'>, Sample -> P Pawar, R Dube, A Joshi, Z Gulhane… - … on Electrical Electronics …, 2024 - ieeexplore.ieee.org\n",
      "snippet: Type -> <class 'str'>, Sample -> The research study investigates the use of cutting-edge technologies like Langchain and … uses Gemini AI to generate MCQs and Langchain for rapid engineering are covered in this …\n",
      "inline_links: Type -> <class 'dict'>, Sample -> {'cited_by': {'cites_id': '9835814645382961985', 'total': 1, 'link': 'https://scholar.google.com/scholar?cites=9835814645382961985&as_sdt=40000005&sciodt=0,22&hl=en&num=20'}, 'related_articles_link': 'https://scholar.google.com/scholar?q=related:Qduivk7Vf4gJ:scholar.google.com/&scioq=Langchain&hl=en&num=20&as_sdt=0,22'}\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect one search result\n",
    "result = gsc_data[\"organic_results\"][1]\n",
    "\n",
    "for key in result:\n",
    "    print(f\"{key}: Type -> {type(result[key])}, Sample -> {result[key]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Citation_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context-Aware Summarization for PDF Documents ...</td>\n",
       "      <td>None</td>\n",
       "      <td>A Ramprasad, P Sivakumar - 2024 International ...</td>\n",
       "      <td>… LangChain, which streamlines the development...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automated Generation and Evaluation of Multipl...</td>\n",
       "      <td>None</td>\n",
       "      <td>P Pawar, R Dube, A Joshi, Z Gulhane… - … on El...</td>\n",
       "      <td>The research study investigates the use of cut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI-enabled semantic web</td>\n",
       "      <td>N Dhanda</td>\n",
       "      <td>A Saeed, N Dhanda, AS Rao… - 2024 2nd Internat...</td>\n",
       "      <td>… The methodology begins by setting up the ess...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penerapan Teknologi LangChain pada Question An...</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian… - … : Indone...</td>\n",
       "      <td>… Therefore, this research aims to create a we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Docxchain: A powerful open-source toolchain fo...</td>\n",
       "      <td>C Yao</td>\n",
       "      <td>C Yao - arXiv preprint arXiv:2310.12430, 2023 ...</td>\n",
       "      <td>In this report, we introduce DocXChain, a powe...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Context-Aware Summarization for PDF Documents ...   \n",
       "1  Automated Generation and Evaluation of Multipl...   \n",
       "2                            AI-enabled semantic web   \n",
       "3  Penerapan Teknologi LangChain pada Question An...   \n",
       "4  Docxchain: A powerful open-source toolchain fo...   \n",
       "\n",
       "                            Authors  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                          N Dhanda   \n",
       "3  S Rahayu, NS Harahap, S Agustian   \n",
       "4                             C Yao   \n",
       "\n",
       "                                         Publication  \\\n",
       "0  A Ramprasad, P Sivakumar - 2024 International ...   \n",
       "1  P Pawar, R Dube, A Joshi, Z Gulhane… - … on El...   \n",
       "2  A Saeed, N Dhanda, AS Rao… - 2024 2nd Internat...   \n",
       "3  S Rahayu, NS Harahap, S Agustian… - … : Indone...   \n",
       "4  C Yao - arXiv preprint arXiv:2310.12430, 2023 ...   \n",
       "\n",
       "                                             Snippet  Citation_Count  \n",
       "0  … LangChain, which streamlines the development...               2  \n",
       "1  The research study investigates the use of cut...               1  \n",
       "2  … The methodology begins by setting up the ess...               3  \n",
       "3  … Therefore, this research aims to create a we...               1  \n",
       "4  In this report, we introduce DocXChain, a powe...               8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data contains your JSON response\n",
    "gsc_results = gsc_data.get(\"organic_results\", [])\n",
    "records = []\n",
    "\n",
    "for item in gsc_results:\n",
    "    # Extract authors names from each author dictionary.\n",
    "    authors_list = item.get(\"authors\", [])\n",
    "    author_names = [author.get(\"name\", \"\") for author in authors_list if isinstance(author, dict)]\n",
    "    \n",
    "    # Initialize citation_count\n",
    "    citation_count = 0\n",
    "    inline_links = item.get(\"inline_links\", {})\n",
    "    # Check if 'cited_by' exists and is a dict, then extract 'total'\n",
    "    if isinstance(inline_links, dict) and 'cited_by' in inline_links:\n",
    "        cited_by = inline_links.get(\"cited_by\")\n",
    "        if isinstance(cited_by, dict):\n",
    "            citation_count = cited_by.get(\"total\", 0)\n",
    "    \n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        \"Authors\": \", \".join(author_names) if author_names else None,\n",
    "        \"Publication\": item.get(\"publication\"),\n",
    "        \"Snippet\": item.get(\"snippet\"),\n",
    "        \"Citation_Count\": citation_count,\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "gcs_df = pd.DataFrame(records)\n",
    "gcs_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'publication' column into three parts\n",
    "gcs_df[['authors', 'venue', 'year_source']] = gcs_df['Publication'].str.split(' - ', n=2, expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Citation_Count</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context-Aware Summarization for PDF Documents ...</td>\n",
       "      <td>None</td>\n",
       "      <td>A Ramprasad, P Sivakumar - 2024 International ...</td>\n",
       "      <td>… LangChain, which streamlines the development...</td>\n",
       "      <td>2</td>\n",
       "      <td>A Ramprasad, P Sivakumar</td>\n",
       "      <td>2024 International Conference on …, 2024</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automated Generation and Evaluation of Multipl...</td>\n",
       "      <td>None</td>\n",
       "      <td>P Pawar, R Dube, A Joshi, Z Gulhane… - … on El...</td>\n",
       "      <td>The research study investigates the use of cut...</td>\n",
       "      <td>1</td>\n",
       "      <td>P Pawar, R Dube, A Joshi, Z Gulhane…</td>\n",
       "      <td>… on Electrical Electronics …, 2024</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI-enabled semantic web</td>\n",
       "      <td>N Dhanda</td>\n",
       "      <td>A Saeed, N Dhanda, AS Rao… - 2024 2nd Internat...</td>\n",
       "      <td>… The methodology begins by setting up the ess...</td>\n",
       "      <td>3</td>\n",
       "      <td>A Saeed, N Dhanda, AS Rao…</td>\n",
       "      <td>2024 2nd International …, 2024</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penerapan Teknologi LangChain pada Question An...</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian… - … : Indone...</td>\n",
       "      <td>… Therefore, this research aims to create a we...</td>\n",
       "      <td>1</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian…</td>\n",
       "      <td>… : Indonesian Journal of …, 2024</td>\n",
       "      <td>journal.irpi.or.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Docxchain: A powerful open-source toolchain fo...</td>\n",
       "      <td>C Yao</td>\n",
       "      <td>C Yao - arXiv preprint arXiv:2310.12430, 2023 ...</td>\n",
       "      <td>In this report, we introduce DocXChain, a powe...</td>\n",
       "      <td>8</td>\n",
       "      <td>C Yao</td>\n",
       "      <td>arXiv preprint arXiv:2310.12430, 2023</td>\n",
       "      <td>arxiv.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Context-Aware Summarization for PDF Documents ...   \n",
       "1  Automated Generation and Evaluation of Multipl...   \n",
       "2                            AI-enabled semantic web   \n",
       "3  Penerapan Teknologi LangChain pada Question An...   \n",
       "4  Docxchain: A powerful open-source toolchain fo...   \n",
       "\n",
       "                            Authors  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                          N Dhanda   \n",
       "3  S Rahayu, NS Harahap, S Agustian   \n",
       "4                             C Yao   \n",
       "\n",
       "                                         Publication  \\\n",
       "0  A Ramprasad, P Sivakumar - 2024 International ...   \n",
       "1  P Pawar, R Dube, A Joshi, Z Gulhane… - … on El...   \n",
       "2  A Saeed, N Dhanda, AS Rao… - 2024 2nd Internat...   \n",
       "3  S Rahayu, NS Harahap, S Agustian… - … : Indone...   \n",
       "4  C Yao - arXiv preprint arXiv:2310.12430, 2023 ...   \n",
       "\n",
       "                                             Snippet  Citation_Count  \\\n",
       "0  … LangChain, which streamlines the development...               2   \n",
       "1  The research study investigates the use of cut...               1   \n",
       "2  … The methodology begins by setting up the ess...               3   \n",
       "3  … Therefore, this research aims to create a we...               1   \n",
       "4  In this report, we introduce DocXChain, a powe...               8   \n",
       "\n",
       "                                authors  \\\n",
       "0              A Ramprasad, P Sivakumar   \n",
       "1  P Pawar, R Dube, A Joshi, Z Gulhane…   \n",
       "2            A Saeed, N Dhanda, AS Rao…   \n",
       "3     S Rahayu, NS Harahap, S Agustian…   \n",
       "4                                 C Yao   \n",
       "\n",
       "                                      venue          year_source  \n",
       "0  2024 International Conference on …, 2024  ieeexplore.ieee.org  \n",
       "1       … on Electrical Electronics …, 2024  ieeexplore.ieee.org  \n",
       "2            2024 2nd International …, 2024  ieeexplore.ieee.org  \n",
       "3         … : Indonesian Journal of …, 2024   journal.irpi.or.id  \n",
       "4     arXiv preprint arXiv:2310.12430, 2023            arxiv.org  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_venue_year(row):\n",
    "    val = row['venue']\n",
    "    \n",
    "    # If it's only a 4-digit year\n",
    "    if val and len(val.strip()) == 4:\n",
    "        return pd.Series({'venue': None, 'year': val.strip()})\n",
    "    \n",
    "    # If it contains a comma, split on the last comma\n",
    "    if isinstance(val, str) and ',' in val:\n",
    "        parts = val.rsplit(',', 1)\n",
    "        return pd.Series({'venue': parts[0].strip(), 'year': parts[1].strip()})\n",
    "    \n",
    "    # Otherwise, return the venue as-is and year as None\n",
    "    return pd.Series({'venue': val, 'year': None})\n",
    "\n",
    "# Apply only after the first split\n",
    "gcs_df[['venue', 'year']] = gcs_df.apply(split_venue_year, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Citation_Count</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year_source</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context-Aware Summarization for PDF Documents ...</td>\n",
       "      <td>None</td>\n",
       "      <td>A Ramprasad, P Sivakumar - 2024 International ...</td>\n",
       "      <td>… LangChain, which streamlines the development...</td>\n",
       "      <td>2</td>\n",
       "      <td>A Ramprasad, P Sivakumar</td>\n",
       "      <td>2024 International Conference on …</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automated Generation and Evaluation of Multipl...</td>\n",
       "      <td>None</td>\n",
       "      <td>P Pawar, R Dube, A Joshi, Z Gulhane… - … on El...</td>\n",
       "      <td>The research study investigates the use of cut...</td>\n",
       "      <td>1</td>\n",
       "      <td>P Pawar, R Dube, A Joshi, Z Gulhane…</td>\n",
       "      <td>… on Electrical Electronics …</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI-enabled semantic web</td>\n",
       "      <td>N Dhanda</td>\n",
       "      <td>A Saeed, N Dhanda, AS Rao… - 2024 2nd Internat...</td>\n",
       "      <td>… The methodology begins by setting up the ess...</td>\n",
       "      <td>3</td>\n",
       "      <td>A Saeed, N Dhanda, AS Rao…</td>\n",
       "      <td>2024 2nd International …</td>\n",
       "      <td>ieeexplore.ieee.org</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penerapan Teknologi LangChain pada Question An...</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian… - … : Indone...</td>\n",
       "      <td>… Therefore, this research aims to create a we...</td>\n",
       "      <td>1</td>\n",
       "      <td>S Rahayu, NS Harahap, S Agustian…</td>\n",
       "      <td>… : Indonesian Journal of …</td>\n",
       "      <td>journal.irpi.or.id</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Docxchain: A powerful open-source toolchain fo...</td>\n",
       "      <td>C Yao</td>\n",
       "      <td>C Yao - arXiv preprint arXiv:2310.12430, 2023 ...</td>\n",
       "      <td>In this report, we introduce DocXChain, a powe...</td>\n",
       "      <td>8</td>\n",
       "      <td>C Yao</td>\n",
       "      <td>arXiv preprint arXiv:2310.12430</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Context-Aware Summarization for PDF Documents ...   \n",
       "1  Automated Generation and Evaluation of Multipl...   \n",
       "2                            AI-enabled semantic web   \n",
       "3  Penerapan Teknologi LangChain pada Question An...   \n",
       "4  Docxchain: A powerful open-source toolchain fo...   \n",
       "\n",
       "                            Authors  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                          N Dhanda   \n",
       "3  S Rahayu, NS Harahap, S Agustian   \n",
       "4                             C Yao   \n",
       "\n",
       "                                         Publication  \\\n",
       "0  A Ramprasad, P Sivakumar - 2024 International ...   \n",
       "1  P Pawar, R Dube, A Joshi, Z Gulhane… - … on El...   \n",
       "2  A Saeed, N Dhanda, AS Rao… - 2024 2nd Internat...   \n",
       "3  S Rahayu, NS Harahap, S Agustian… - … : Indone...   \n",
       "4  C Yao - arXiv preprint arXiv:2310.12430, 2023 ...   \n",
       "\n",
       "                                             Snippet  Citation_Count  \\\n",
       "0  … LangChain, which streamlines the development...               2   \n",
       "1  The research study investigates the use of cut...               1   \n",
       "2  … The methodology begins by setting up the ess...               3   \n",
       "3  … Therefore, this research aims to create a we...               1   \n",
       "4  In this report, we introduce DocXChain, a powe...               8   \n",
       "\n",
       "                                authors                               venue  \\\n",
       "0              A Ramprasad, P Sivakumar  2024 International Conference on …   \n",
       "1  P Pawar, R Dube, A Joshi, Z Gulhane…       … on Electrical Electronics …   \n",
       "2            A Saeed, N Dhanda, AS Rao…            2024 2nd International …   \n",
       "3     S Rahayu, NS Harahap, S Agustian…         … : Indonesian Journal of …   \n",
       "4                                 C Yao     arXiv preprint arXiv:2310.12430   \n",
       "\n",
       "           year_source  year  \n",
       "0  ieeexplore.ieee.org  2024  \n",
       "1  ieeexplore.ieee.org  2024  \n",
       "2  ieeexplore.ieee.org  2024  \n",
       "3   journal.irpi.or.id  2024  \n",
       "4            arxiv.org  2023  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_df.to_excel('gcs_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IEEE Xplore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 403\n",
      "Raw Response: <h1>Developer Inactive</h1>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"shrw4werbra7k85hqn6ghzr2\"\n",
    "response = requests.get(\n",
    "    \"http://ieeexploreapi.ieee.org/api/v1/search/articles\",\n",
    "    params={\"querytext\": \"AI\", \"apikey\": API_KEY}\n",
    ")\n",
    "\n",
    "print(\"Status Code:\", response.status_code)  # Check if 200, 403, 429, etc.\n",
    "print(\"Raw Response:\", response.text)  # See what's actually returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**google news**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['error'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "params = {\n",
    "  \"engine\": \"google_news\",\n",
    "  \"q\": \"Jeff Bezos news\",\n",
    "  \"location\": \"New York,United States\",\n",
    "  \"api_key\": \"Qeg1buThqizr68MqzRKFLpEN\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "news_data = response.json()\n",
    "news_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['position', 'title', 'link', 'source', 'date', 'snippet', 'favicon', 'thumbnail'])\n"
     ]
    }
   ],
   "source": [
    "if 'organic_results' in news_data and news_data['organic_results'] : \n",
    "  print(news_data['organic_results'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: Type -> <class 'int'>, Sample -> 5\n",
      "title: Type -> <class 'str'>, Sample -> MacKenzie Scott Has Given Away $19 Billion Since Divorce from Jeff Bezos 6 Years Ago\n",
      "link: Type -> <class 'str'>, Sample -> https://people.com/since-jeff-bezos-divorce-mackenzie-scott-given-away-over-19-billion-11709699\n",
      "source: Type -> <class 'str'>, Sample -> People.com\n",
      "date: Type -> <class 'str'>, Sample -> 14 hours ago\n",
      "snippet: Type -> <class 'str'>, Sample -> MacKenzie Scott has \"transformed\" philanthropy since her divorce from Jeff Bezos in 2019: In the past six years, she's donated $19 billion...\n",
      "favicon: Type -> <class 'str'>, Sample -> data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAYFBMVEUAru////+Z3vgctvAAm9YAcZsYfqSJ2fdr0PUIsO/j9v2u5Pk7wPKZxtew0+ATjLl0scgtiqy52OPM4+sReqIAl8+JvdBJmbcAeKRbpL8Af64AkMYAqOcRlscikLkAod0uTMfTAAAAYElEQVQYlY3OSQ6AIBBEUUoGZwFnBeX+txQ30CvjX750OsXYr8oiVtUZGry1GTqgHwCdgAPGADYQGCdgXgjEeikIrJuVO/1xnM75BAUwXXTYu+P2BLhWSi70JAgh6MVnD4zGAyMiy5nfAAAAAElFTkSuQmCC\n",
      "thumbnail: Type -> <class 'str'>, Sample -> data:image/jpeg;base64,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\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect one search result\n",
    "news_result = news_data[\"organic_results\"][4]\n",
    "\n",
    "for key in news_result:\n",
    "    print(f\"{key}: Type -> {type(news_result[key])}, Sample -> {news_result[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creating large language model applications utilizing lan...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>… LangChain has been widely recognized in the AI communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic literature review langchain proposed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>While systematic literature reviews are frequently carri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LangChain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>… This paper provides an in-depth analysis of LangChain’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automating Customer Service using LangChain: Building cu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In the digital age, the dynamics of customer service are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LangChain v0. 3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>… This paper provides an in-depth analysis of LangChain’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title Source  Date  \\\n",
       "0  Creating large language model applications utilizing lan...   None  None   \n",
       "1              Systematic literature review langchain proposed   None  None   \n",
       "2                                                    LangChain   None  None   \n",
       "3  Automating Customer Service using LangChain: Building cu...   None  None   \n",
       "4                                              LangChain v0. 3   None  None   \n",
       "\n",
       "                                                       Snippet  \n",
       "0  … LangChain has been widely recognized in the AI communi...  \n",
       "1  While systematic literature reviews are frequently carri...  \n",
       "2  … This paper provides an in-depth analysis of LangChain’...  \n",
       "3  In the digital age, the dynamics of customer service are...  \n",
       "4  … This paper provides an in-depth analysis of LangChain’...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose news_results is the list from your API response (i.e., response.json()['news_results'])\n",
    "news_results = data.get(\"organic_results\", [])\n",
    "\n",
    "# Create a list of dictionaries with only the required keys\n",
    "records = []\n",
    "for item in news_results:\n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        \"Source\": item.get(\"source\"),\n",
    "        \"Date\": item.get(\"date\"),\n",
    "        \"Snippet\": item.get(\"snippet\")\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creating large language model applications utilizing lan...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>… LangChain has been widely recognized in the AI communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic literature review langchain proposed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>While systematic literature reviews are frequently carri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LangChain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>… This paper provides an in-depth analysis of LangChain’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automating Customer Service using LangChain: Building cu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In the digital age, the dynamics of customer service are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LangChain v0. 3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>… This paper provides an in-depth analysis of LangChain’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title Source  Date  \\\n",
       "0  Creating large language model applications utilizing lan...   None  None   \n",
       "1              Systematic literature review langchain proposed   None  None   \n",
       "2                                                    LangChain   None  None   \n",
       "3  Automating Customer Service using LangChain: Building cu...   None  None   \n",
       "4                                              LangChain v0. 3   None  None   \n",
       "\n",
       "                                                       Snippet  \n",
       "0  … LangChain has been widely recognized in the AI communi...  \n",
       "1  While systematic literature reviews are frequently carri...  \n",
       "2  … This paper provides an in-depth analysis of LangChain’...  \n",
       "3  In the digital age, the dynamics of customer service are...  \n",
       "4  … This paper provides an in-depth analysis of LangChain’...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use the correct key for news results\n",
    "news_results = data.get(\"organic_results\", [])\n",
    "\n",
    "records = []\n",
    "for item in news_results:\n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        \"Source\": item.get(\"source\"),\n",
    "        \"Date\": item.get(\"date\"),\n",
    "        \"Snippet\": item.get(\"snippet\")\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys in news items:\n",
      "dict_keys(['position', 'title', 'link', 'source', 'date', 'snippet', 'favicon', 'thumbnail'])\n",
      "\n",
      "Sample item structure:\n",
      "{'position': 1, 'title': \"Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 billion after Donald Trump's ‘discounted’ reciprocal\", 'link': 'https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-jeff-bezos-and-mark-zuckerberg-lose-42-6-billion-as-trump-announces-discounted-reciprocal-tariffs/articleshow/120010512.cms', 'source': 'Times of India', 'date': '12 hours ago', 'snippet': 'TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk collectively lost $42.6 billion in a day due to new tariffs announced by President...', 'favicon': 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAZlBMVEXMAQDMAADNBgbKAADJAADLAADIAAD43t722trmmJf////llJTODw7VR0f21tbsr6/on5/uuLjdbWzUPj7xwcHQKSn+8/PQHx7dZ2bccXH65eXSJCTQFhbooqLji4vee3v76+vYVVUTPZcvAAAAhklEQVQYlY2O2w6DMAxDkzpJGd0obMC4lF3+/ydX4Im9bJYiR0dKbKKD2NFvwLw67b4BQKAMPouyGNOlir6O1lxvbYe2v9NgobChrgxjb8ELKU6F2FRD5zIFj/wjA5kWaFfyCigDwyPP87WdsIvFrLKM7yZp9ClHQ3IFqIL39Y/qBzlyX/oAugAFO4H++JIAAAAASUVORK5CYII=', 'thumbnail': 'data:image/jpeg;base64,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'}\n"
     ]
    }
   ],
   "source": [
    "# Print the structure of the first news result\n",
    "if news_data.get(\"organic_results\"):\n",
    "    first_item = news_data[\"organic_results\"][0]\n",
    "    print(\"Available keys in news items:\")\n",
    "    print(first_item.keys())\n",
    "    \n",
    "    print(\"\\nSample item structure:\")\n",
    "    print(first_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...</td>\n",
       "      <td>Times of India</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Post Opinions section anxiously awaits new le...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>The Washington Post has faced an exodus of talent in rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What to know about Bezos Academy, the Jeff Bezos prescho...</td>\n",
       "      <td>The Arizona Republic</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Bezos Academy will open in Glendale in September and off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Under Trump and Musk, billionaires wield unprecedented i...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>Government officials and contractors long controlled spy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacKenzie Scott Has Given Away $19 Billion Since Divorce...</td>\n",
       "      <td>People.com</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>MacKenzie Scott has \"transformed\" philanthropy since her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title  \\\n",
       "0  Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...   \n",
       "1  Washington Post Opinions section anxiously awaits new le...   \n",
       "2  What to know about Bezos Academy, the Jeff Bezos prescho...   \n",
       "3  Under Trump and Musk, billionaires wield unprecedented i...   \n",
       "4  MacKenzie Scott Has Given Away $19 Billion Since Divorce...   \n",
       "\n",
       "                 Source          Date  \\\n",
       "0        Times of India  12 hours ago   \n",
       "1              Fox News    3 days ago   \n",
       "2  The Arizona Republic     1 day ago   \n",
       "3          The Guardian  21 hours ago   \n",
       "4            People.com  14 hours ago   \n",
       "\n",
       "                                                       Snippet  \n",
       "0  TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...  \n",
       "1  The Washington Post has faced an exodus of talent in rec...  \n",
       "2  Bezos Academy will open in Glendale in September and off...  \n",
       "3  Government officials and contractors long controlled spy...  \n",
       "4  MacKenzie Scott has \"transformed\" philanthropy since her...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "news_results = news_data.get(\"organic_results\", [])\n",
    "\n",
    "records = []\n",
    "for item in news_results:\n",
    "    # Different APIs use different key names - adjust accordingly\n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        # Common variations for source\n",
    "        \"Source\": item.get(\"source\") or  # Nested source\n",
    "                  item.get(\"publisher\") or\n",
    "                  item.get(\"site\"),\n",
    "        # Common variations for date\n",
    "        \"Date\": item.get(\"date\") or\n",
    "                item.get(\"published_date\") or\n",
    "                item.get(\"pub_date\"),\n",
    "        \"Snippet\": item.get(\"snippet\"),\n",
    "        # Additional useful fields\n",
    "        \n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>RelativeDate</th>\n",
       "      <th>FormattedDate</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...</td>\n",
       "      <td>Times of India</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>2025-04-07 03:14</td>\n",
       "      <td>TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Post Opinions section anxiously awaits new le...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>2025-04-04 15:14</td>\n",
       "      <td>The Washington Post has faced an exodus of talent in rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What to know about Bezos Academy, the Jeff Bezos prescho...</td>\n",
       "      <td>The Arizona Republic</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>2025-04-06 15:14</td>\n",
       "      <td>Bezos Academy will open in Glendale in September and off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Under Trump and Musk, billionaires wield unprecedented i...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>2025-04-06 18:14</td>\n",
       "      <td>Government officials and contractors long controlled spy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacKenzie Scott Has Given Away $19 Billion Since Divorce...</td>\n",
       "      <td>People.com</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>2025-04-07 01:14</td>\n",
       "      <td>MacKenzie Scott has \"transformed\" philanthropy since her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Title  \\\n",
       "0  Elon Musk, Jeff Bezos and Mark Zuckerberg lose $42.6 bil...   \n",
       "1  Washington Post Opinions section anxiously awaits new le...   \n",
       "2  What to know about Bezos Academy, the Jeff Bezos prescho...   \n",
       "3  Under Trump and Musk, billionaires wield unprecedented i...   \n",
       "4  MacKenzie Scott Has Given Away $19 Billion Since Divorce...   \n",
       "\n",
       "                 Source  RelativeDate     FormattedDate  \\\n",
       "0        Times of India  12 hours ago  2025-04-07 03:14   \n",
       "1              Fox News    3 days ago  2025-04-04 15:14   \n",
       "2  The Arizona Republic     1 day ago  2025-04-06 15:14   \n",
       "3          The Guardian  21 hours ago  2025-04-06 18:14   \n",
       "4            People.com  14 hours ago  2025-04-07 01:14   \n",
       "\n",
       "                                                       Snippet  \n",
       "0  TECH NEWS : Mark Zuckerberg, Jeff Bezos, and Elon Musk c...  \n",
       "1  The Washington Post has faced an exodus of talent in rec...  \n",
       "2  Bezos Academy will open in Glendale in September and off...  \n",
       "3  Government officials and contractors long controlled spy...  \n",
       "4  MacKenzie Scott has \"transformed\" philanthropy since her...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://www.searchapi.io/api/v1/search\"\n",
    "params = {\n",
    "    \"engine\": \"google_news\",\n",
    "    \"q\": \"Jeff Bezos news\",\n",
    "    \"location\": \"New York,United States\",\n",
    "    \"api_key\": \"Qeg1buThqizr68MqzRKFLpEN\"\n",
    "}\n",
    "\n",
    "# Fetch data from API\n",
    "response = requests.get(url, params=params)\n",
    "news_data = response.json()\n",
    "\n",
    "# Process news results\n",
    "news_results = news_data.get(\"organic_results\", [])\n",
    "\n",
    "def parse_relative_date(date_str):\n",
    "    \"\"\"Convert relative date strings to datetime objects\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        # Parse relative date (e.g., \"1 day ago\")\n",
    "        parsed_date = dateparser.parse(date_str)\n",
    "        \n",
    "        # For dates without year information, ensure we don't default to 2000\n",
    "        if parsed_date and parsed_date.year == 2000:\n",
    "            current_year = datetime.now().year\n",
    "            parsed_date = parsed_date.replace(year=current_year)\n",
    "            \n",
    "        return parsed_date\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "records = []\n",
    "for item in news_results:\n",
    "    record = {\n",
    "        \"Title\": item.get(\"title\"),\n",
    "        \"Source\": item.get(\"source\"),\n",
    "        \"RelativeDate\": item.get(\"date\"),  # Original string (e.g., \"1 day ago\")\n",
    "        \"Date\": parse_relative_date(item.get(\"date\")),  # Parsed datetime\n",
    "        \"Snippet\": item.get(\"snippet\"),\n",
    "        \"Link\": item.get(\"link\"),\n",
    "        \"HasThumbnail\": bool(item.get(\"thumbnail\")),\n",
    "        \"Position\": item.get(\"position\")\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Format the datetime for display\n",
    "df['FormattedDate'] = df['Date'].dt.strftime('%Y-%m-%d %H:%M') if not df.empty else None\n",
    "\n",
    "# Show results\n",
    "df[['Title', 'Source', 'RelativeDate', 'FormattedDate', 'Snippet']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
