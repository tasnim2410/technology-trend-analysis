{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Initialize the scraper\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     scraper \u001b[38;5;241m=\u001b[39m \u001b[43mEspacenetScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set headless to False to see the browser in action\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame with family numbers and publication numbers\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily_number\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m087517563\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manother_family_number\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Replace with actual family numbers\u001b[39;00m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_number\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGB2631304A\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manother_publication_number\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with actual publication numbers\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m, in \u001b[0;36mEspacenetScraper.__init__\u001b[1;34m(self, headless)\u001b[0m\n\u001b[0;32m     17\u001b[0m     options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--headless\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Run in headless mode\u001b[39;00m\n\u001b[0;32m     19\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--disable-blink-features=AutomationControlled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;241m=\u001b[39m \u001b[43muc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mset_page_load_timeout(\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mset_window_size(\u001b[38;5;241m1300\u001b[39m, \u001b[38;5;241m800\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\undetected_chromedriver\\__init__.py:258\u001b[0m, in \u001b[0;36mChrome.__init__\u001b[1;34m(self, options, user_data_dir, driver_executable_path, browser_executable_path, port, enable_cdp_events, desired_capabilities, advanced_elements, keep_alive, log_level, headless, version_main, patcher_force_close, suppress_welcome, use_subprocess, debug, no_sandbox, user_multi_procs, **kw)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatcher \u001b[38;5;241m=\u001b[39m Patcher(\n\u001b[0;32m    252\u001b[0m     executable_path\u001b[38;5;241m=\u001b[39mdriver_executable_path,\n\u001b[0;32m    253\u001b[0m     force\u001b[38;5;241m=\u001b[39mpatcher_force_close,\n\u001b[0;32m    254\u001b[0m     version_main\u001b[38;5;241m=\u001b[39mversion_main,\n\u001b[0;32m    255\u001b[0m     user_multi_procs\u001b[38;5;241m=\u001b[39muser_multi_procs,\n\u001b[0;32m    256\u001b[0m )\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# self.patcher.auto(user_multiprocess = user_multi_num_procs)\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# self.patcher = patcher\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\undetected_chromedriver\\patcher.py:178\u001b[0m, in \u001b[0;36mPatcher.auto\u001b[1;34m(self, executable_path, force, version_main, _)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion_main \u001b[38;5;241m=\u001b[39m release\u001b[38;5;241m.\u001b[39mversion[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion_full \u001b[38;5;241m=\u001b[39m release\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munzip_package(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\undetected_chromedriver\\patcher.py:287\u001b[0m, in \u001b[0;36mPatcher.fetch_package\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m     download_url \u001b[38;5;241m%\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion_full\u001b[38;5;241m.\u001b[39mvstring, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplatform_name, zip_name)\n\u001b[0;32m    286\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m download_url)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "class EspacenetScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options.\"\"\"\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(30)\n",
    "        self.driver.set_window_size(1300, 800)\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"Add a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, url):\n",
    "        \"\"\"Navigate to the given URL and return the page HTML.\"\"\"\n",
    "        try:\n",
    "            print(f\"Navigating to: {url}\")\n",
    "            self.driver.get(url)\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "        # Switch to the iframe (you may need to adjust the selector)\n",
    "            iframe = WebDriverWait(self.driver, 30).until(\n",
    "              EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "                 )\n",
    "            self.driver.switch_to.frame(iframe)\n",
    "\n",
    "        # Wait for a specific element inside the iframe that indicates the table is loaded\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h3\"))  # Adjust selector as needed\n",
    "                 )\n",
    "\n",
    "        # Add a random delay to mimic human behavior\n",
    "            self.add_random_delay(3, 5)\n",
    "\n",
    "        # Return the page HTML of the iframe\n",
    "            page_html = self.driver.page_source\n",
    "\n",
    "        # Switch back to the default content\n",
    "            self.driver.switch_to.default_content()\n",
    "\n",
    "            return page_html\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for the page to load.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Look for the <li> element with the specific class attributes\n",
    "        li_element = soup.find('li', class_=lambda x: x and 'classitem' in x and 'clearfix' in x and 'level-7' in x)\n",
    "\n",
    "        if li_element:\n",
    "        # Find the <a> tag inside <li>\n",
    "         symbol_classref = li_element.find('a', class_='symbol classref')\n",
    "        \n",
    "        # Ensure symbol_classref exists before checking its text\n",
    "         if symbol_classref and symbol_classref.get_text(strip=True) == 'B67D9/00':\n",
    "            title_span = li_element.find('span', class_='title')\n",
    "            \n",
    "            # Ensure title_span exists before searching for raw-text span\n",
    "            if title_span:\n",
    "                raw_text_span = title_span.find('span', class_='raw-text')\n",
    "                \n",
    "                # Ensure raw_text_span exists before returning its text\n",
    "                if raw_text_span:\n",
    "                    return raw_text_span.get_text(strip=True)\n",
    "\n",
    "         return None  # Return None if nothing was found\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the scraper\n",
    "    scraper = EspacenetScraper(headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    # Create a DataFrame with family numbers and publication numbers\n",
    "    data = {\n",
    "        'family_number': ['087517563', 'another_family_number'],  # Replace with actual family numbers\n",
    "        'publication_number': ['GB2631304A', 'another_publication_number']  # Replace with actual publication numbers\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create a new column for family members\n",
    "    #df['classification'] = None\n",
    "\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            # Construct the URL using family number and publication number\n",
    "            url = f'https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M8/04201'\n",
    "\n",
    "            # Get the page HTML\n",
    "            html = scraper.get_page_html(url)\n",
    "        if html:\n",
    "            print(\"Page HTML retrieved successfully.\")\n",
    "            # # Save the HTML to a file for inspection\n",
    "            # with open(\"classification_search.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "            #     file.write(html)\n",
    "            # print(\"HTML saved to 'classification_search.html'.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")\n",
    "        print(html)\n",
    "\n",
    "    # Display the DataFrame with\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fixing multiple spans in the title element issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M8/04201\n",
      "Timed out waiting for the page to load.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M8/04201\n",
      "Page HTML retrieved successfully.\n",
      "Classification data: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M8/00': 'Fuel cells Manufacture thereof'}\n",
      "HTML saved to 'classification_search.html'.\n",
      "Scraper closed.\n",
      "{'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M8/00': 'Fuel cells Manufacture thereof'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "class EspacenetScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options.\"\"\"\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(30)\n",
    "        self.driver.set_window_size(1300, 800)\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"Add a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, url):\n",
    "        \"\"\"Navigate to the given URL and return the page HTML.\"\"\"\n",
    "        try:\n",
    "            print(f\"Navigating to: {url}\")\n",
    "            self.driver.get(url)\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "            # Switch to the iframe (you may need to adjust the selector)\n",
    "            iframe = WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "            )\n",
    "            self.driver.switch_to.frame(iframe)\n",
    "\n",
    "            # Wait for a specific element inside the iframe that indicates the table is loaded\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h3\"))  # Adjust selector as needed\n",
    "            )\n",
    "\n",
    "            # Add a random delay to mimic human behavior\n",
    "            self.add_random_delay(3, 5)\n",
    "\n",
    "            # Return the page HTML of the iframe\n",
    "            page_html = self.driver.page_source\n",
    "\n",
    "            # Switch back to the default content\n",
    "            self.driver.switch_to.default_content()\n",
    "\n",
    "            return page_html\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for the page to load.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        \"\"\"\n",
    "        Parses the HTML content and extracts a dictionary of classification symbols and titles.\n",
    "\n",
    "        Args:\n",
    "            html (str): The HTML content to parse.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are classification symbols and values are their corresponding titles.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        result_dict = {}\n",
    "\n",
    "        # Find all classitem divs\n",
    "        for classitem in soup.find_all('div', class_='classitem'):\n",
    "            titlebar = classitem.find('div', class_='titlebar')\n",
    "            symbol_holder = classitem.find('div', class_='symbol-holder')\n",
    "\n",
    "            if titlebar and symbol_holder:\n",
    "                # Find all <span class=\"raw-text\"> elements inside the titlebar\n",
    "                raw_text_spans = titlebar.find_all('span', class_='raw-text')\n",
    "                # Combine the text from all raw-text spans into one sentence\n",
    "                combined_text = ' '.join(span.get_text(strip=True) for span in raw_text_spans)\n",
    "\n",
    "                symbol_ref = symbol_holder.find('a', class_='symbol classref')\n",
    "\n",
    "                if combined_text and symbol_ref:\n",
    "                    key = symbol_ref.get_text(strip=True)  # Symbol is the key\n",
    "                    value = combined_text  # Combined text from all raw-text spans is the value\n",
    "                    result_dict[key] = value\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the scraper\n",
    "    scraper = EspacenetScraper(headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    # Create a DataFrame with family numbers and publication numbers\n",
    "    data = {\n",
    "        'family_number': ['087517563', 'another_family_number'],  # Replace with actual family numbers\n",
    "        'publication_number': ['GB2631304A', 'another_publication_number']  # Replace with actual publication numbers\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create a new column for family members\n",
    "    df['classification'] = None\n",
    "\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            # Construct the URL using family number and publication number\n",
    "            url = f'https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M8/04201'\n",
    "\n",
    "            # Get the page HTML\n",
    "            html = scraper.get_page_html(url)\n",
    "            if html:\n",
    "                print(\"Page HTML retrieved successfully.\")\n",
    "                # Parse the HTML to extract classification data\n",
    "                classification_data = scraper.parse_html(html)\n",
    "                print(\"Classification data:\", classification_data)\n",
    "\n",
    "                # Save the classification data to the DataFrame\n",
    "                df.at[index, 'classification'] = str(classification_data)  # Convert dict to string for storage\n",
    "\n",
    "                # # Save the HTML to a file for inspection\n",
    "                # with open(\"classification_search.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "                #     file.write(html)\n",
    "                # print(\"HTML saved to 'classification_search.html'.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")\n",
    "        print(classification_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 'ELECTRICITY',\n",
       " 'H01': 'ELECTRIC ELEMENTS',\n",
       " 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY',\n",
       " 'H01M8/00': 'Fuel cells Manufacture thereof'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making the input a dynamic link \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M8/00\n",
      "Timed out waiting for the page to load.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M4/00\n",
      "Page HTML for CPC H01M4/00 retrieved successfully.\n",
      "Classification data for CPC H01M4/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M4/00': 'Electrodes'}\n",
      "HTML for CPC H01M4/00 saved to 'classification_search_H01M4_00.html'.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M10/00\n",
      "Page HTML for CPC H01M10/00 retrieved successfully.\n",
      "Classification data for CPC H01M10/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M10/00': 'Secondary cells Manufacture thereof'}\n",
      "HTML for CPC H01M10/00 saved to 'classification_search_H01M10_00.html'.\n",
      "Scraper closed.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "class EspacenetScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options.\"\"\"\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(30)\n",
    "        self.driver.set_window_size(1300, 800)\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"Add a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, url):\n",
    "        \"\"\"Navigate to the given URL and return the page HTML.\"\"\"\n",
    "        try:\n",
    "            print(f\"Navigating to: {url}\")\n",
    "            self.driver.get(url)\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "            # Switch to the iframe (you may need to adjust the selector)\n",
    "            iframe = WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "            )\n",
    "            self.driver.switch_to.frame(iframe)\n",
    "\n",
    "            # Wait for a specific element inside the iframe that indicates the table is loaded\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h3\"))  # Adjust selector as needed\n",
    "            )\n",
    "\n",
    "            # Add a random delay to mimic human behavior\n",
    "            self.add_random_delay(3, 5)\n",
    "\n",
    "            # Return the page HTML of the iframe\n",
    "            page_html = self.driver.page_source\n",
    "\n",
    "            # Switch back to the default content\n",
    "            self.driver.switch_to.default_content()\n",
    "\n",
    "            return page_html\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for the page to load.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        \"\"\"\n",
    "        Parses the HTML content and extracts a dictionary of classification symbols and titles.\n",
    "\n",
    "        Args:\n",
    "            html (str): The HTML content to parse.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are classification symbols and values are their corresponding titles.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        result_dict = {}\n",
    "\n",
    "        # Find all classitem divs\n",
    "        for classitem in soup.find_all('div', class_='classitem'):\n",
    "            titlebar = classitem.find('div', class_='titlebar')\n",
    "            symbol_holder = classitem.find('div', class_='symbol-holder')\n",
    "\n",
    "            if titlebar and symbol_holder:\n",
    "                # Find all <span class=\"raw-text\"> elements inside the titlebar\n",
    "                raw_text_spans = titlebar.find_all('span', class_='raw-text')\n",
    "                # Combine the text from all raw-text spans into one sentence\n",
    "                combined_text = ' '.join(span.get_text(strip=True) for span in raw_text_spans)\n",
    "\n",
    "                symbol_ref = symbol_holder.find('a', class_='symbol classref')\n",
    "\n",
    "                if combined_text and symbol_ref:\n",
    "                    key = symbol_ref.get_text(strip=True)  # Symbol is the key\n",
    "                    value = combined_text  # Combined text from all raw-text spans is the value\n",
    "                    result_dict[key] = value\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the scraper\n",
    "    scraper = EspacenetScraper(headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    # List of CPC symbols to process\n",
    "    cpc_list = [\"H01M8/00\", \"H01M4/00\", \"H01M10/00\"]  # Add more CPC symbols as needed\n",
    "\n",
    "    try:\n",
    "        for cpc_symbol in cpc_list:\n",
    "            # Construct the URL using the CPC symbol\n",
    "            url = f'https://worldwide.espacenet.com/patent/cpc-browser#!/CPC={cpc_symbol}'\n",
    "\n",
    "            # Get the page HTML\n",
    "            html = scraper.get_page_html(url)\n",
    "            if html:\n",
    "                print(f\"Page HTML for CPC {cpc_symbol} retrieved successfully.\")\n",
    "                # Parse the HTML to extract classification data\n",
    "                classification_data = scraper.parse_html(html)\n",
    "                print(f\"Classification data for CPC {cpc_symbol}: {classification_data}\")\n",
    "\n",
    "                # # Save the HTML to a file for inspection\n",
    "                # with open(f\"classification_search_{cpc_symbol.replace('/', '_')}.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "                #     file.write(html)\n",
    "                # print(f\"HTML for CPC {cpc_symbol} saved to 'classification_search_{cpc_symbol.replace('/', '_')}.html'.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fixing resuts saving issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=Y02E60/50\n",
      "Timed out waiting for the page to load.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M4/00\n",
      "Page HTML for CPC H01M4/00 retrieved successfully.\n",
      "Classification data for CPC H01M4/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M4/00': 'Electrodes'}\n",
      "HTML for CPC H01M4/00 saved to 'classification_search_H01M4_00.html'.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M10/00\n",
      "Page HTML for CPC H01M10/00 retrieved successfully.\n",
      "Classification data for CPC H01M10/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M10/00': 'Secondary cells Manufacture thereof'}\n",
      "HTML for CPC H01M10/00 saved to 'classification_search_H01M10_00.html'.\n",
      "Scraper closed.\n",
      "All results:\n",
      "CPC H01M4/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M4/00': 'Electrodes'}\n",
      "CPC H01M10/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M10/00': 'Secondary cells Manufacture thereof'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "class EspacenetScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options.\"\"\"\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(30)\n",
    "        self.driver.set_window_size(1300, 800)\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"Add a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, url):\n",
    "        \"\"\"Navigate to the given URL and return the page HTML.\"\"\"\n",
    "        try:\n",
    "            print(f\"Navigating to: {url}\")\n",
    "            self.driver.get(url)\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "            # Switch to the iframe (you may need to adjust the selector)\n",
    "            iframe = WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "            )\n",
    "            self.driver.switch_to.frame(iframe)\n",
    "\n",
    "            # Wait for a specific element inside the iframe that indicates the table is loaded\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"li\"))  # Adjust selector as needed\n",
    "            )\n",
    "\n",
    "            # Add a random delay to mimic human behavior\n",
    "            self.add_random_delay(3, 5)\n",
    "\n",
    "            # Return the page HTML of the iframe\n",
    "            page_html = self.driver.page_source\n",
    "\n",
    "            # Switch back to the default content\n",
    "            self.driver.switch_to.default_content()\n",
    "\n",
    "            return page_html\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for the page to load.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        \"\"\"\n",
    "        Parses the HTML content and extracts a dictionary of classification symbols and titles.\n",
    "\n",
    "        Args:\n",
    "            html (str): The HTML content to parse.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are classification symbols and values are their corresponding titles.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        result_dict = {}\n",
    "\n",
    "        # Find all classitem divs\n",
    "        for classitem in soup.find_all('div', class_='classitem'):\n",
    "            titlebar = classitem.find('div', class_='titlebar')\n",
    "            symbol_holder = classitem.find('div', class_='symbol-holder')\n",
    "\n",
    "            if titlebar and symbol_holder:\n",
    "                # Find all <span class=\"raw-text\"> elements inside the titlebar\n",
    "                raw_text_spans = titlebar.find_all('span', class_='raw-text')\n",
    "                # Combine the text from all raw-text spans into one sentence\n",
    "                combined_text = ' '.join(span.get_text(strip=True) for span in raw_text_spans)\n",
    "\n",
    "                symbol_ref = symbol_holder.find('a', class_='symbol classref')\n",
    "\n",
    "                if combined_text and symbol_ref:\n",
    "                    key = symbol_ref.get_text(strip=True)  # Symbol is the key\n",
    "                    value = combined_text  # Combined text from all raw-text spans is the value\n",
    "                    result_dict[key] = value\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the scraper\n",
    "    scraper = EspacenetScraper(headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    # List of CPC symbols to process\n",
    "    cpc_list = [\"Y02E60/50\", \"H01M4/00\", \"H01M10/00\"]  # Add more CPC symbols as needed\n",
    "\n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "\n",
    "    try:\n",
    "        for cpc_symbol in cpc_list:\n",
    "            # Construct the URL using the CPC symbol\n",
    "            url = f'https://worldwide.espacenet.com/patent/cpc-browser#!/CPC={cpc_symbol}'\n",
    "\n",
    "            # Get the page HTML\n",
    "            html = scraper.get_page_html(url)\n",
    "            if html:\n",
    "                print(f\"Page HTML for CPC {cpc_symbol} retrieved successfully.\")\n",
    "                # Parse the HTML to extract classification data\n",
    "                classification_data = scraper.parse_html(html)\n",
    "                print(f\"Classification data for CPC {cpc_symbol}: {classification_data}\")\n",
    "\n",
    "                # Save the results to the all_results dictionary\n",
    "                all_results[cpc_symbol] = classification_data\n",
    "\n",
    "                # # Save the HTML to a file for inspection\n",
    "                # with open(f\"classification_search_{cpc_symbol.replace('/', '_')}.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "                #     file.write(html)\n",
    "                # print(f\"HTML for CPC {cpc_symbol} saved to 'classification_search_{cpc_symbol.replace('/', '_')}.html'.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")\n",
    "\n",
    "    # Print all results\n",
    "    print(\"All results:\")\n",
    "    for cpc_symbol, data in all_results.items():\n",
    "        print(f\"CPC {cpc_symbol}: {data}\")\n",
    "\n",
    "    # Now you can use the `all_results` variable later in your code\n",
    "    # Example: Accessing the results for a specific CPC symbol\n",
    "    if \"H01M8/00\" in all_results:\n",
    "        print(\"Data for H01M8/00:\", all_results[\"H01M8/00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H01M4/00': {'H': 'ELECTRICITY',\n",
       "  'H01': 'ELECTRIC ELEMENTS',\n",
       "  'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY',\n",
       "  'H01M4/00': 'Electrodes'},\n",
       " 'H01M10/00': {'H': 'ELECTRICITY',\n",
       "  'H01': 'ELECTRIC ELEMENTS',\n",
       "  'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY',\n",
       "  'H01M10/00': 'Secondary cells Manufacture thereof'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fixing timedout for the first value of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H04B1/20 (Attempt 1)\n",
      "Page HTML for CPC H04B1/20 retrieved successfully.\n",
      "Classification data for CPC H04B1/20: {'H': 'ELECTRICITY', 'H04': 'ELECTRIC COMMUNICATION TECHNIQUE', 'H04B': 'TRANSMISSION', 'H04B1/00': 'Details of transmission systems, not covered by a single one of groupsH04B3/00-H04B13/00 Details of transmission systems not characterised by the medium used for transmission'}\n",
      "HTML for CPC H04B1/20 saved to 'classification_search_H04B1_20.html'.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M4/00 (Attempt 1)\n",
      "Page HTML for CPC H01M4/00 retrieved successfully.\n",
      "Classification data for CPC H01M4/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M4/00': 'Electrodes'}\n",
      "HTML for CPC H01M4/00 saved to 'classification_search_H01M4_00.html'.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=H01M10/00 (Attempt 1)\n",
      "Page HTML for CPC H01M10/00 retrieved successfully.\n",
      "Classification data for CPC H01M10/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M10/00': 'Secondary cells Manufacture thereof'}\n",
      "HTML for CPC H01M10/00 saved to 'classification_search_H01M10_00.html'.\n",
      "Scraper closed.\n",
      "All results:\n",
      "CPC H04B1/20: {'H': 'ELECTRICITY', 'H04': 'ELECTRIC COMMUNICATION TECHNIQUE', 'H04B': 'TRANSMISSION', 'H04B1/00': 'Details of transmission systems, not covered by a single one of groupsH04B3/00-H04B13/00 Details of transmission systems not characterised by the medium used for transmission'}\n",
      "CPC H01M4/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M4/00': 'Electrodes'}\n",
      "CPC H01M10/00: {'H': 'ELECTRICITY', 'H01': 'ELECTRIC ELEMENTS', 'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY', 'H01M10/00': 'Secondary cells Manufacture thereof'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "class EspacenetScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options.\"\"\"\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(60)  # Increase page load timeout\n",
    "        self.driver.set_window_size(1300, 800)\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"Add a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, url, retries=3):\n",
    "        \"\"\"\n",
    "        Navigate to the given URL and return the page HTML.\n",
    "        Retry the request if it fails.\n",
    "        \"\"\"\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                print(f\"Navigating to: {url} (Attempt {attempt + 1})\")\n",
    "                self.driver.get(url)\n",
    "                WebDriverWait(self.driver, 60).until(  # Increase timeout\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "\n",
    "                # Add a small delay before switching to the iframe\n",
    "                self.add_random_delay(2, 4)\n",
    "\n",
    "                # Switch to the iframe\n",
    "                iframe = WebDriverWait(self.driver, 60).until(  # Increase timeout\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "                )\n",
    "                self.driver.switch_to.frame(iframe)\n",
    "\n",
    "                # Wait for a specific element inside the iframe that indicates the table is loaded\n",
    "                WebDriverWait(self.driver, 60).until(  # Increase timeout\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.cpcbrowser-results-holder\"))  # More specific element\n",
    "                )\n",
    "\n",
    "                # Add a random delay to mimic human behavior\n",
    "                self.add_random_delay(3, 5)\n",
    "\n",
    "                # Return the page HTML of the iframe\n",
    "                page_html = self.driver.page_source\n",
    "\n",
    "                # Switch back to the default content\n",
    "                self.driver.switch_to.default_content()\n",
    "\n",
    "                return page_html\n",
    "\n",
    "            except TimeoutException:\n",
    "                print(f\"Timed out waiting for the page to load (Attempt {attempt + 1}).\")\n",
    "                if attempt < retries - 1:\n",
    "                    print(\"Retrying...\")\n",
    "                else:\n",
    "                    print(\"Max retries reached. Moving to the next URL.\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return None\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        \"\"\"\n",
    "        Parses the HTML content and extracts a dictionary of classification symbols and titles.\n",
    "\n",
    "        Args:\n",
    "            html (str): The HTML content to parse.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are classification symbols and values are their corresponding titles.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        result_dict = {}\n",
    "\n",
    "        # Find all classitem divs\n",
    "        for classitem in soup.find_all('div', class_='classitem'):\n",
    "            titlebar = classitem.find('div', class_='titlebar')\n",
    "            symbol_holder = classitem.find('div', class_='symbol-holder')\n",
    "\n",
    "            if titlebar and symbol_holder:\n",
    "                # Find all <span class=\"raw-text\"> elements inside the titlebar\n",
    "                raw_text_spans = titlebar.find_all('span', class_='raw-text')\n",
    "                # Combine the text from all raw-text spans into one sentence\n",
    "                combined_text = ' '.join(span.get_text(strip=True) for span in raw_text_spans)\n",
    "\n",
    "                symbol_ref = symbol_holder.find('a', class_='symbol classref')\n",
    "\n",
    "                if combined_text and symbol_ref:\n",
    "                    key = symbol_ref.get_text(strip=True)  # Symbol is the key\n",
    "                    value = combined_text  # Combined text from all raw-text spans is the value\n",
    "                    result_dict[key] = value\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the scraper\n",
    "    scraper = EspacenetScraper(headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    # List of CPC symbols to process\n",
    "    cpc_list = [\"H04B1/20\", \"H01M4/00\", \"H01M10/00\"]  # Add more CPC symbols as needed\n",
    "\n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "\n",
    "    try:\n",
    "        for cpc_symbol in cpc_list:\n",
    "            # Construct the URL using the CPC symbol\n",
    "            url = f'https://worldwide.espacenet.com/patent/cpc-browser#!/CPC={cpc_symbol}'\n",
    "\n",
    "            # Get the page HTML\n",
    "            html = scraper.get_page_html(url)\n",
    "            if html:\n",
    "                print(f\"Page HTML for CPC {cpc_symbol} retrieved successfully.\")\n",
    "                # Parse the HTML to extract classification data\n",
    "                classification_data = scraper.parse_html(html)\n",
    "                print(f\"Classification data for CPC {cpc_symbol}: {classification_data}\")\n",
    "\n",
    "                # Save the results to the all_results dictionary\n",
    "                all_results[cpc_symbol] = classification_data\n",
    "\n",
    "                # # Save the HTML to a file for inspection\n",
    "                # with open(f\"classification_search_{cpc_symbol.replace('/', '_')}.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "                #     file.write(html)\n",
    "                # print(f\"HTML for CPC {cpc_symbol} saved to 'classification_search_{cpc_symbol.replace('/', '_')}.html'.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")\n",
    "\n",
    "    # Print all results\n",
    "    print(\"All results:\")\n",
    "    for cpc_symbol, data in all_results.items():\n",
    "        print(f\"CPC {cpc_symbol}: {data}\")\n",
    "\n",
    "    # Now you can use the `all_results` variable later in your code\n",
    "    # Example: Accessing the results for a specific CPC symbol\n",
    "    if \"H01M8/00\" in all_results:\n",
    "        print(\"Data for H01M8/00:\", all_results[\"H01M8/00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B60K15/013': {'B': 'PERFORMING OPERATIONS TRANSPORTING',\n",
       "  'B60': 'VEHICLES IN GENERAL',\n",
       "  'B60K': 'ARRANGEMENT OR MOUNTING OF PROPULSION UNITS OR OF TRANSMISSIONS IN VEHICLES ARRANGEMENT OR MOUNTING OF PLURAL DIVERSE PRIME-MOVERS IN VEHICLES AUXILIARY DRIVES FOR VEHICLES INSTRUMENTATION OR DASHBOARDS FOR VEHICLES ARRANGEMENTS IN CONNECTION WITH COOLING, AIR INTAKE, GAS EXHAUST OR FUEL SUPPLY OF PROPULSION UNITS IN VEHICLES',\n",
       "  'B60K11/00': 'Arrangements in connection with cooling, air intake, gas exhaust, fuel supply, or power supply of propulsion units in vehicles',\n",
       "  'B60K15/00': 'Arrangement in connection with fuel supply of combustion engines or other fuel consuming energy converters, e.g. fuel cells Mounting or construction of fuel tanks'},\n",
       " 'H01M4/00': {'H': 'ELECTRICITY',\n",
       "  'H01': 'ELECTRIC ELEMENTS',\n",
       "  'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY',\n",
       "  'H01M4/00': 'Electrodes'},\n",
       " 'H01M10/00': {'H': 'ELECTRICITY',\n",
       "  'H01': 'ELECTRIC ELEMENTS',\n",
       "  'H01M': 'PROCESSES OR MEANS, e.g. BATTERIES, FOR THE DIRECT CONVERSION OF CHEMICAL ENERGY INTO ELECTRICAL ENERGY',\n",
       "  'H01M10/00': 'Secondary cells Manufacture thereof'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=A (Attempt 1)\n",
      "Timed out waiting for the page to load (Attempt 1).\n",
      "Retrying...\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=A (Attempt 2)\n",
      "Page HTML for CPC A retrieved successfully.\n",
      "Classification data for CPC A: {'A': 'HUMAN NECESSITIES', 'A01': 'AGRICULTURE FORESTRY ANIMAL HUSBANDRY HUNTING TRAPPING FISHING', 'A21': 'BAKING EDIBLE DOUGHS', 'A22': 'BUTCHERING MEAT TREATMENT PROCESSING POULTRY OR FISH', 'A23': 'FOODS OR FOODSTUFFS TREATMENT THEREOF, NOT COVERED BY OTHER CLASSES', 'A24': \"TOBACCO CIGARS CIGARETTES SIMULATED SMOKING DEVICES SMOKERS' REQUISITES\", 'A41': 'WEARING APPAREL', 'A42': 'HEADWEAR', 'A43': 'FOOTWEAR', 'A44': 'HABERDASHERY JEWELLERY', 'A45': 'HAND OR TRAVELLING ARTICLES', 'A46': 'BRUSHWARE', 'A47': 'FURNITURE DOMESTIC ARTICLES OR APPLIANCES COFFEE MILLS SPICE MILLS SUCTION CLEANERS IN GENERAL', 'A61': 'MEDICAL OR VETERINARY SCIENCE HYGIENE', 'A62': 'LIFE-SAVING FIRE-FIGHTING', 'A63': 'SPORTS GAMES AMUSEMENTS', 'A99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}\n",
      "HTML for CPC A saved to 'classification_search_A.html'.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=B (Attempt 1)\n",
      "Page HTML for CPC B retrieved successfully.\n",
      "Classification data for CPC B: {'B': 'PERFORMING OPERATIONS TRANSPORTING', 'B01': 'PHYSICAL OR CHEMICAL PROCESSES OR APPARATUS IN GENERAL', 'B02': 'CRUSHING, PULVERISING, OR DISINTEGRATING PREPARATORY TREATMENT OF GRAIN FOR MILLING', 'B03': 'SEPARATION OF SOLID MATERIALS USING LIQUIDS OR USING PNEUMATIC TABLES OR JIGS MAGNETIC OR ELECTROSTATIC SEPARATION OF SOLID MATERIALS FROM SOLID MATERIALS OR FLUIDS SEPARATION BY HIGH-VOLTAGE ELECTRIC FIELDS', 'B04': 'CENTRIFUGAL APPARATUS OR MACHINES FOR CARRYING-OUT PHYSICAL OR CHEMICAL PROCESSES', 'B05': 'SPRAYING OR ATOMISING IN GENERAL APPLYING FLUENT MATERIALS TO SURFACES, IN GENERAL', 'B06': 'GENERATING OR TRANSMITTING MECHANICAL VIBRATIONS IN GENERAL', 'B07': 'SEPARATING SOLIDS FROM SOLIDS SORTING', 'B08': 'CLEANING', 'B09': 'DISPOSAL OF SOLID WASTE RECLAMATION OF CONTAMINATED SOIL', 'B21': 'MECHANICAL METAL-WORKING WITHOUT ESSENTIALLY REMOVING MATERIAL PUNCHING METAL', 'B22': 'CASTING POWDER METALLURGY', 'B23': 'MACHINE TOOLS METAL-WORKING NOT OTHERWISE PROVIDED FOR', 'B24': 'GRINDING POLISHING', 'B25': 'HAND TOOLS PORTABLE POWER-DRIVEN TOOLS MANIPULATORS', 'B26': 'HAND CUTTING TOOLS CUTTING SEVERING', 'B27': 'WORKING OR PRESERVING WOOD OR SIMILAR MATERIAL NAILING OR STAPLING MACHINES IN GENERAL', 'B28': 'WORKING CEMENT, CLAY, OR STONE', 'B29': 'WORKING OF PLASTICS WORKING OF SUBSTANCES IN A PLASTIC STATE IN GENERAL', 'B30': 'PRESSES', 'B31': 'MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIAL WORKED IN A MANNER ANALOGOUS TO PAPER WORKING PAPER, CARDBOARD OR MATERIAL WORKED IN A MANNER ANALOGOUS TO PAPER', 'B32': 'LAYERED PRODUCTS', 'B33': 'ADDITIVE MANUFACTURING TECHNOLOGY', 'B41': 'PRINTING LINING MACHINES TYPEWRITERS STAMPS', 'B42': 'BOOKBINDING ALBUMS FILES SPECIAL PRINTED MATTER', 'B43': 'WRITING OR DRAWING IMPLEMENTS BUREAU ACCESSORIES', 'B44': 'DECORATIVE ARTS', 'B60': 'VEHICLES IN GENERAL', 'B61': 'RAILWAYS', 'B62': 'LAND VEHICLES FOR TRAVELLING OTHERWISE THAN ON RAILS', 'B63': 'SHIPS OR OTHER WATERBORNE VESSELS RELATED EQUIPMENT', 'B64': 'AIRCRAFT AVIATION COSMONAUTICS', 'B65': 'CONVEYING PACKING STORING HANDLING THIN OR FILAMENTARY MATERIAL', 'B66': 'HOISTING LIFTING HAULING', 'B67': 'OPENING, CLOSING OR CLEANING BOTTLES, JARS OR SIMILAR CONTAINERS LIQUID HANDLING', 'B68': 'SADDLERY UPHOLSTERY', 'B81': 'MICROSTRUCTURAL TECHNOLOGY', 'B82': 'NANOTECHNOLOGY', 'B99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}\n",
      "HTML for CPC B saved to 'classification_search_B.html'.\n",
      "Navigating to: https://worldwide.espacenet.com/patent/cpc-browser#!/CPC=C (Attempt 1)\n",
      "Page HTML for CPC C retrieved successfully.\n",
      "Classification data for CPC C: {'C': 'CHEMISTRY METALLURGY', 'C01': 'INORGANIC CHEMISTRY', 'C02': 'TREATMENT OF WATER, WASTE WATER, SEWAGE, OR SLUDGE', 'C03': 'GLASS MINERAL OR SLAG WOOL', 'C04': 'CEMENTS CONCRETE ARTIFICIAL STONE CERAMICS REFRACTORIES', 'C05': 'FERTILISERS MANUFACTURE THEREOF', 'C06': 'EXPLOSIVES MATCHES', 'C07': 'ORGANIC CHEMISTRY', 'C08': 'ORGANIC MACROMOLECULAR COMPOUNDS THEIR PREPARATION OR CHEMICAL WORKING-UP COMPOSITIONS BASED THEREON', 'C09': 'DYES PAINTS POLISHES NATURAL RESINS ADHESIVES COMPOSITIONS NOT OTHERWISE PROVIDED FOR APPLICATIONS OF MATERIALS NOT OTHERWISE PROVIDED FOR', 'C10': 'PETROLEUM, GAS OR COKE INDUSTRIES TECHNICAL GASES CONTAINING CARBON MONOXIDE FUELS LUBRICANTS PEAT', 'C11': 'ANIMAL OR VEGETABLE OILS, FATS, FATTY SUBSTANCES OR WAXES FATTY ACIDS THEREFROM DETERGENTS CANDLES', 'C12': 'BIOCHEMISTRY BEER SPIRITS WINE VINEGAR MICROBIOLOGY ENZYMOLOGY MUTATION OR GENETIC ENGINEERING', 'C13': 'SUGAR INDUSTRY', 'C14': 'SKINS HIDES PELTS LEATHER', 'C21': 'METALLURGY OF IRON', 'C22': 'METALLURGY FERROUS OR NON-FERROUS ALLOYS TREATMENT OF ALLOYS OR NON-FERROUS METALS', 'C23': 'COATING METALLIC MATERIAL COATING MATERIAL WITH METALLIC MATERIAL CHEMICAL SURFACE TREATMENT DIFFUSION TREATMENT OF METALLIC MATERIAL COATING BY VACUUM EVAPORATION, BY SPUTTERING, BY ION IMPLANTATION OR BY CHEMICAL VAPOUR DEPOSITION, IN GENERAL INHIBITING CORROSION OF METALLIC MATERIAL OR INCRUSTATION IN GENERAL', 'C25': 'ELECTROLYTIC OR ELECTROPHORETIC PROCESSES APPARATUS THEREFOR', 'C30': 'CRYSTAL GROWTH', 'C40': 'COMBINATORIAL TECHNOLOGY', 'C99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}\n",
      "HTML for CPC C saved to 'classification_search_C.html'.\n",
      "Scraper closed.\n",
      "All results:\n",
      "CPC A: {'A': 'HUMAN NECESSITIES', 'A01': 'AGRICULTURE FORESTRY ANIMAL HUSBANDRY HUNTING TRAPPING FISHING', 'A21': 'BAKING EDIBLE DOUGHS', 'A22': 'BUTCHERING MEAT TREATMENT PROCESSING POULTRY OR FISH', 'A23': 'FOODS OR FOODSTUFFS TREATMENT THEREOF, NOT COVERED BY OTHER CLASSES', 'A24': \"TOBACCO CIGARS CIGARETTES SIMULATED SMOKING DEVICES SMOKERS' REQUISITES\", 'A41': 'WEARING APPAREL', 'A42': 'HEADWEAR', 'A43': 'FOOTWEAR', 'A44': 'HABERDASHERY JEWELLERY', 'A45': 'HAND OR TRAVELLING ARTICLES', 'A46': 'BRUSHWARE', 'A47': 'FURNITURE DOMESTIC ARTICLES OR APPLIANCES COFFEE MILLS SPICE MILLS SUCTION CLEANERS IN GENERAL', 'A61': 'MEDICAL OR VETERINARY SCIENCE HYGIENE', 'A62': 'LIFE-SAVING FIRE-FIGHTING', 'A63': 'SPORTS GAMES AMUSEMENTS', 'A99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}\n",
      "CPC B: {'B': 'PERFORMING OPERATIONS TRANSPORTING', 'B01': 'PHYSICAL OR CHEMICAL PROCESSES OR APPARATUS IN GENERAL', 'B02': 'CRUSHING, PULVERISING, OR DISINTEGRATING PREPARATORY TREATMENT OF GRAIN FOR MILLING', 'B03': 'SEPARATION OF SOLID MATERIALS USING LIQUIDS OR USING PNEUMATIC TABLES OR JIGS MAGNETIC OR ELECTROSTATIC SEPARATION OF SOLID MATERIALS FROM SOLID MATERIALS OR FLUIDS SEPARATION BY HIGH-VOLTAGE ELECTRIC FIELDS', 'B04': 'CENTRIFUGAL APPARATUS OR MACHINES FOR CARRYING-OUT PHYSICAL OR CHEMICAL PROCESSES', 'B05': 'SPRAYING OR ATOMISING IN GENERAL APPLYING FLUENT MATERIALS TO SURFACES, IN GENERAL', 'B06': 'GENERATING OR TRANSMITTING MECHANICAL VIBRATIONS IN GENERAL', 'B07': 'SEPARATING SOLIDS FROM SOLIDS SORTING', 'B08': 'CLEANING', 'B09': 'DISPOSAL OF SOLID WASTE RECLAMATION OF CONTAMINATED SOIL', 'B21': 'MECHANICAL METAL-WORKING WITHOUT ESSENTIALLY REMOVING MATERIAL PUNCHING METAL', 'B22': 'CASTING POWDER METALLURGY', 'B23': 'MACHINE TOOLS METAL-WORKING NOT OTHERWISE PROVIDED FOR', 'B24': 'GRINDING POLISHING', 'B25': 'HAND TOOLS PORTABLE POWER-DRIVEN TOOLS MANIPULATORS', 'B26': 'HAND CUTTING TOOLS CUTTING SEVERING', 'B27': 'WORKING OR PRESERVING WOOD OR SIMILAR MATERIAL NAILING OR STAPLING MACHINES IN GENERAL', 'B28': 'WORKING CEMENT, CLAY, OR STONE', 'B29': 'WORKING OF PLASTICS WORKING OF SUBSTANCES IN A PLASTIC STATE IN GENERAL', 'B30': 'PRESSES', 'B31': 'MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIAL WORKED IN A MANNER ANALOGOUS TO PAPER WORKING PAPER, CARDBOARD OR MATERIAL WORKED IN A MANNER ANALOGOUS TO PAPER', 'B32': 'LAYERED PRODUCTS', 'B33': 'ADDITIVE MANUFACTURING TECHNOLOGY', 'B41': 'PRINTING LINING MACHINES TYPEWRITERS STAMPS', 'B42': 'BOOKBINDING ALBUMS FILES SPECIAL PRINTED MATTER', 'B43': 'WRITING OR DRAWING IMPLEMENTS BUREAU ACCESSORIES', 'B44': 'DECORATIVE ARTS', 'B60': 'VEHICLES IN GENERAL', 'B61': 'RAILWAYS', 'B62': 'LAND VEHICLES FOR TRAVELLING OTHERWISE THAN ON RAILS', 'B63': 'SHIPS OR OTHER WATERBORNE VESSELS RELATED EQUIPMENT', 'B64': 'AIRCRAFT AVIATION COSMONAUTICS', 'B65': 'CONVEYING PACKING STORING HANDLING THIN OR FILAMENTARY MATERIAL', 'B66': 'HOISTING LIFTING HAULING', 'B67': 'OPENING, CLOSING OR CLEANING BOTTLES, JARS OR SIMILAR CONTAINERS LIQUID HANDLING', 'B68': 'SADDLERY UPHOLSTERY', 'B81': 'MICROSTRUCTURAL TECHNOLOGY', 'B82': 'NANOTECHNOLOGY', 'B99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}\n",
      "CPC C: {'C': 'CHEMISTRY METALLURGY', 'C01': 'INORGANIC CHEMISTRY', 'C02': 'TREATMENT OF WATER, WASTE WATER, SEWAGE, OR SLUDGE', 'C03': 'GLASS MINERAL OR SLAG WOOL', 'C04': 'CEMENTS CONCRETE ARTIFICIAL STONE CERAMICS REFRACTORIES', 'C05': 'FERTILISERS MANUFACTURE THEREOF', 'C06': 'EXPLOSIVES MATCHES', 'C07': 'ORGANIC CHEMISTRY', 'C08': 'ORGANIC MACROMOLECULAR COMPOUNDS THEIR PREPARATION OR CHEMICAL WORKING-UP COMPOSITIONS BASED THEREON', 'C09': 'DYES PAINTS POLISHES NATURAL RESINS ADHESIVES COMPOSITIONS NOT OTHERWISE PROVIDED FOR APPLICATIONS OF MATERIALS NOT OTHERWISE PROVIDED FOR', 'C10': 'PETROLEUM, GAS OR COKE INDUSTRIES TECHNICAL GASES CONTAINING CARBON MONOXIDE FUELS LUBRICANTS PEAT', 'C11': 'ANIMAL OR VEGETABLE OILS, FATS, FATTY SUBSTANCES OR WAXES FATTY ACIDS THEREFROM DETERGENTS CANDLES', 'C12': 'BIOCHEMISTRY BEER SPIRITS WINE VINEGAR MICROBIOLOGY ENZYMOLOGY MUTATION OR GENETIC ENGINEERING', 'C13': 'SUGAR INDUSTRY', 'C14': 'SKINS HIDES PELTS LEATHER', 'C21': 'METALLURGY OF IRON', 'C22': 'METALLURGY FERROUS OR NON-FERROUS ALLOYS TREATMENT OF ALLOYS OR NON-FERROUS METALS', 'C23': 'COATING METALLIC MATERIAL COATING MATERIAL WITH METALLIC MATERIAL CHEMICAL SURFACE TREATMENT DIFFUSION TREATMENT OF METALLIC MATERIAL COATING BY VACUUM EVAPORATION, BY SPUTTERING, BY ION IMPLANTATION OR BY CHEMICAL VAPOUR DEPOSITION, IN GENERAL INHIBITING CORROSION OF METALLIC MATERIAL OR INCRUSTATION IN GENERAL', 'C25': 'ELECTROLYTIC OR ELECTROPHORETIC PROCESSES APPARATUS THEREFOR', 'C30': 'CRYSTAL GROWTH', 'C40': 'COMBINATORIAL TECHNOLOGY', 'C99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "class EspacenetScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        \"\"\"Initialize the scraper with configurable options.\"\"\"\n",
    "        options = uc.ChromeOptions()\n",
    "        if headless:\n",
    "            options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.driver = uc.Chrome(options=options)\n",
    "        self.driver.set_page_load_timeout(60)  # Increase page load timeout\n",
    "        self.driver.set_window_size(1300, 800)\n",
    "\n",
    "    def add_random_delay(self, min_seconds=1, max_seconds=3):\n",
    "        \"\"\"Add a random delay to mimic human behavior.\"\"\"\n",
    "        time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "    def get_page_html(self, url, retries=3):\n",
    "        \"\"\"\n",
    "        Navigate to the given URL and return the page HTML.\n",
    "        Retry the request if it fails.\n",
    "        \"\"\"\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                print(f\"Navigating to: {url} (Attempt {attempt + 1})\")\n",
    "                self.driver.get(url)\n",
    "                WebDriverWait(self.driver, 60).until(  # Increase timeout\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "\n",
    "                # Add a small delay before switching to the iframe\n",
    "                self.add_random_delay(2, 4)\n",
    "\n",
    "                # Switch to the iframe\n",
    "                iframe = WebDriverWait(self.driver, 60).until(  # Increase timeout\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "                )\n",
    "                self.driver.switch_to.frame(iframe)\n",
    "\n",
    "                # Wait for a specific element inside the iframe that indicates the table is loaded\n",
    "                WebDriverWait(self.driver, 60).until(  # Increase timeout\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.cpcbrowser-results-holder\"))  # More specific element\n",
    "                )\n",
    "\n",
    "                # Add a random delay to mimic human behavior\n",
    "                self.add_random_delay(3, 5)\n",
    "\n",
    "                # Return the page HTML of the iframe\n",
    "                page_html = self.driver.page_source\n",
    "\n",
    "                # Switch back to the default content\n",
    "                self.driver.switch_to.default_content()\n",
    "\n",
    "                return page_html\n",
    "\n",
    "            except TimeoutException:\n",
    "                print(f\"Timed out waiting for the page to load (Attempt {attempt + 1}).\")\n",
    "                if attempt < retries - 1:\n",
    "                    print(\"Retrying...\")\n",
    "                else:\n",
    "                    print(\"Max retries reached. Moving to the next URL.\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return None\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        \"\"\"\n",
    "        Parses the HTML content and extracts a dictionary of classification symbols and titles.\n",
    "\n",
    "        Args:\n",
    "            html (str): The HTML content to parse.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are classification symbols and values are their corresponding titles.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        result_dict = {}\n",
    "\n",
    "        # Find all classitem divs\n",
    "        for classitem in soup.find_all('div', class_='classitem'):\n",
    "            titlebar = classitem.find('div', class_='titlebar')\n",
    "            symbol_holder = classitem.find('div', class_='symbol-holder')\n",
    "\n",
    "            if titlebar and symbol_holder:\n",
    "                # Find all <span class=\"raw-text\"> elements inside the titlebar\n",
    "                raw_text_spans = titlebar.find_all('span', class_='raw-text')\n",
    "                # Combine the text from all raw-text spans into one sentence\n",
    "                combined_text = ' '.join(span.get_text(strip=True) for span in raw_text_spans)\n",
    "\n",
    "                symbol_ref = symbol_holder.find('a', class_='symbol classref')\n",
    "\n",
    "                if combined_text and symbol_ref:\n",
    "                    key = symbol_ref.get_text(strip=True)  # Symbol is the key\n",
    "                    value = combined_text  # Combined text from all raw-text spans is the value\n",
    "                    result_dict[key] = value\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser when done.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize the scraper\n",
    "    scraper = EspacenetScraper(headless=False)  # Set headless to False to see the browser in action\n",
    "\n",
    "    # List of CPC symbols to process\n",
    "    cpc_list = [\"A\", \"B\", \"C\"]  # Add more CPC symbols as needed\n",
    "\n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "\n",
    "    try:\n",
    "        for cpc_symbol in cpc_list:\n",
    "            # Construct the URL using the CPC symbol\n",
    "            url = f'https://worldwide.espacenet.com/patent/cpc-browser#!/CPC={cpc_symbol}'\n",
    "\n",
    "            # Get the page HTML\n",
    "            html = scraper.get_page_html(url)\n",
    "            if html:\n",
    "                print(f\"Page HTML for CPC {cpc_symbol} retrieved successfully.\")\n",
    "                # Parse the HTML to extract classification data\n",
    "                classification_data = scraper.parse_html(html)\n",
    "                print(f\"Classification data for CPC {cpc_symbol}: {classification_data}\")\n",
    "\n",
    "                # Save the results to the all_results dictionary\n",
    "                all_results[cpc_symbol] = classification_data\n",
    "\n",
    "                # # Save the HTML to a file for inspection\n",
    "                # with open(f\"classification_search_{cpc_symbol.replace('/', '_')}.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "                #     file.write(html)\n",
    "                # print(f\"HTML for CPC {cpc_symbol} saved to 'classification_search_{cpc_symbol.replace('/', '_')}.html'.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        scraper.close()\n",
    "        print(\"Scraper closed.\")\n",
    "\n",
    "    # Print all results\n",
    "    print(\"All results:\")\n",
    "    for cpc_symbol, data in all_results.items():\n",
    "        print(f\"CPC {cpc_symbol}: {data}\")\n",
    "\n",
    "    # Now you can use the `all_results` variable later in your code\n",
    "    # Example: Accessing the results for a specific CPC symbol\n",
    "    if \"H01M8/00\" in all_results:\n",
    "        print(\"Data for H01M8/00:\", all_results[\"H01M8/00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'A': 'HUMAN NECESSITIES',\n",
       "  'A01': 'AGRICULTURE FORESTRY ANIMAL HUSBANDRY HUNTING TRAPPING FISHING',\n",
       "  'A21': 'BAKING EDIBLE DOUGHS',\n",
       "  'A22': 'BUTCHERING MEAT TREATMENT PROCESSING POULTRY OR FISH',\n",
       "  'A23': 'FOODS OR FOODSTUFFS TREATMENT THEREOF, NOT COVERED BY OTHER CLASSES',\n",
       "  'A24': \"TOBACCO CIGARS CIGARETTES SIMULATED SMOKING DEVICES SMOKERS' REQUISITES\",\n",
       "  'A41': 'WEARING APPAREL',\n",
       "  'A42': 'HEADWEAR',\n",
       "  'A43': 'FOOTWEAR',\n",
       "  'A44': 'HABERDASHERY JEWELLERY',\n",
       "  'A45': 'HAND OR TRAVELLING ARTICLES',\n",
       "  'A46': 'BRUSHWARE',\n",
       "  'A47': 'FURNITURE DOMESTIC ARTICLES OR APPLIANCES COFFEE MILLS SPICE MILLS SUCTION CLEANERS IN GENERAL',\n",
       "  'A61': 'MEDICAL OR VETERINARY SCIENCE HYGIENE',\n",
       "  'A62': 'LIFE-SAVING FIRE-FIGHTING',\n",
       "  'A63': 'SPORTS GAMES AMUSEMENTS',\n",
       "  'A99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'},\n",
       " 'B': {'B': 'PERFORMING OPERATIONS TRANSPORTING',\n",
       "  'B01': 'PHYSICAL OR CHEMICAL PROCESSES OR APPARATUS IN GENERAL',\n",
       "  'B02': 'CRUSHING, PULVERISING, OR DISINTEGRATING PREPARATORY TREATMENT OF GRAIN FOR MILLING',\n",
       "  'B03': 'SEPARATION OF SOLID MATERIALS USING LIQUIDS OR USING PNEUMATIC TABLES OR JIGS MAGNETIC OR ELECTROSTATIC SEPARATION OF SOLID MATERIALS FROM SOLID MATERIALS OR FLUIDS SEPARATION BY HIGH-VOLTAGE ELECTRIC FIELDS',\n",
       "  'B04': 'CENTRIFUGAL APPARATUS OR MACHINES FOR CARRYING-OUT PHYSICAL OR CHEMICAL PROCESSES',\n",
       "  'B05': 'SPRAYING OR ATOMISING IN GENERAL APPLYING FLUENT MATERIALS TO SURFACES, IN GENERAL',\n",
       "  'B06': 'GENERATING OR TRANSMITTING MECHANICAL VIBRATIONS IN GENERAL',\n",
       "  'B07': 'SEPARATING SOLIDS FROM SOLIDS SORTING',\n",
       "  'B08': 'CLEANING',\n",
       "  'B09': 'DISPOSAL OF SOLID WASTE RECLAMATION OF CONTAMINATED SOIL',\n",
       "  'B21': 'MECHANICAL METAL-WORKING WITHOUT ESSENTIALLY REMOVING MATERIAL PUNCHING METAL',\n",
       "  'B22': 'CASTING POWDER METALLURGY',\n",
       "  'B23': 'MACHINE TOOLS METAL-WORKING NOT OTHERWISE PROVIDED FOR',\n",
       "  'B24': 'GRINDING POLISHING',\n",
       "  'B25': 'HAND TOOLS PORTABLE POWER-DRIVEN TOOLS MANIPULATORS',\n",
       "  'B26': 'HAND CUTTING TOOLS CUTTING SEVERING',\n",
       "  'B27': 'WORKING OR PRESERVING WOOD OR SIMILAR MATERIAL NAILING OR STAPLING MACHINES IN GENERAL',\n",
       "  'B28': 'WORKING CEMENT, CLAY, OR STONE',\n",
       "  'B29': 'WORKING OF PLASTICS WORKING OF SUBSTANCES IN A PLASTIC STATE IN GENERAL',\n",
       "  'B30': 'PRESSES',\n",
       "  'B31': 'MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIAL WORKED IN A MANNER ANALOGOUS TO PAPER WORKING PAPER, CARDBOARD OR MATERIAL WORKED IN A MANNER ANALOGOUS TO PAPER',\n",
       "  'B32': 'LAYERED PRODUCTS',\n",
       "  'B33': 'ADDITIVE MANUFACTURING TECHNOLOGY',\n",
       "  'B41': 'PRINTING LINING MACHINES TYPEWRITERS STAMPS',\n",
       "  'B42': 'BOOKBINDING ALBUMS FILES SPECIAL PRINTED MATTER',\n",
       "  'B43': 'WRITING OR DRAWING IMPLEMENTS BUREAU ACCESSORIES',\n",
       "  'B44': 'DECORATIVE ARTS',\n",
       "  'B60': 'VEHICLES IN GENERAL',\n",
       "  'B61': 'RAILWAYS',\n",
       "  'B62': 'LAND VEHICLES FOR TRAVELLING OTHERWISE THAN ON RAILS',\n",
       "  'B63': 'SHIPS OR OTHER WATERBORNE VESSELS RELATED EQUIPMENT',\n",
       "  'B64': 'AIRCRAFT AVIATION COSMONAUTICS',\n",
       "  'B65': 'CONVEYING PACKING STORING HANDLING THIN OR FILAMENTARY MATERIAL',\n",
       "  'B66': 'HOISTING LIFTING HAULING',\n",
       "  'B67': 'OPENING, CLOSING OR CLEANING BOTTLES, JARS OR SIMILAR CONTAINERS LIQUID HANDLING',\n",
       "  'B68': 'SADDLERY UPHOLSTERY',\n",
       "  'B81': 'MICROSTRUCTURAL TECHNOLOGY',\n",
       "  'B82': 'NANOTECHNOLOGY',\n",
       "  'B99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'},\n",
       " 'C': {'C': 'CHEMISTRY METALLURGY',\n",
       "  'C01': 'INORGANIC CHEMISTRY',\n",
       "  'C02': 'TREATMENT OF WATER, WASTE WATER, SEWAGE, OR SLUDGE',\n",
       "  'C03': 'GLASS MINERAL OR SLAG WOOL',\n",
       "  'C04': 'CEMENTS CONCRETE ARTIFICIAL STONE CERAMICS REFRACTORIES',\n",
       "  'C05': 'FERTILISERS MANUFACTURE THEREOF',\n",
       "  'C06': 'EXPLOSIVES MATCHES',\n",
       "  'C07': 'ORGANIC CHEMISTRY',\n",
       "  'C08': 'ORGANIC MACROMOLECULAR COMPOUNDS THEIR PREPARATION OR CHEMICAL WORKING-UP COMPOSITIONS BASED THEREON',\n",
       "  'C09': 'DYES PAINTS POLISHES NATURAL RESINS ADHESIVES COMPOSITIONS NOT OTHERWISE PROVIDED FOR APPLICATIONS OF MATERIALS NOT OTHERWISE PROVIDED FOR',\n",
       "  'C10': 'PETROLEUM, GAS OR COKE INDUSTRIES TECHNICAL GASES CONTAINING CARBON MONOXIDE FUELS LUBRICANTS PEAT',\n",
       "  'C11': 'ANIMAL OR VEGETABLE OILS, FATS, FATTY SUBSTANCES OR WAXES FATTY ACIDS THEREFROM DETERGENTS CANDLES',\n",
       "  'C12': 'BIOCHEMISTRY BEER SPIRITS WINE VINEGAR MICROBIOLOGY ENZYMOLOGY MUTATION OR GENETIC ENGINEERING',\n",
       "  'C13': 'SUGAR INDUSTRY',\n",
       "  'C14': 'SKINS HIDES PELTS LEATHER',\n",
       "  'C21': 'METALLURGY OF IRON',\n",
       "  'C22': 'METALLURGY FERROUS OR NON-FERROUS ALLOYS TREATMENT OF ALLOYS OR NON-FERROUS METALS',\n",
       "  'C23': 'COATING METALLIC MATERIAL COATING MATERIAL WITH METALLIC MATERIAL CHEMICAL SURFACE TREATMENT DIFFUSION TREATMENT OF METALLIC MATERIAL COATING BY VACUUM EVAPORATION, BY SPUTTERING, BY ION IMPLANTATION OR BY CHEMICAL VAPOUR DEPOSITION, IN GENERAL INHIBITING CORROSION OF METALLIC MATERIAL OR INCRUSTATION IN GENERAL',\n",
       "  'C25': 'ELECTROLYTIC OR ELECTROPHORETIC PROCESSES APPARATUS THEREFOR',\n",
       "  'C30': 'CRYSTAL GROWTH',\n",
       "  'C40': 'COMBINATORIAL TECHNOLOGY',\n",
       "  'C99': 'SUBJECT MATTER NOT OTHERWISE PROVIDED FOR IN THIS SECTION'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dict_to_dataframe(all_results):\n",
    "    \"\"\"\n",
    "    Converts the `all_results` dictionary into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        all_results (dict): A dictionary where keys are CPC symbols and values are dictionaries\n",
    "                            of classification data (symbols and titles).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns 'CPC Symbol' and 'Classification Title'.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the data\n",
    "    cpc_symbols = []\n",
    "    classification_titles = []\n",
    "\n",
    "    # Iterate through the all_results dictionary\n",
    "    for cpc_symbol, classification_data in all_results.items():\n",
    "        for symbol, title in classification_data.items():\n",
    "            cpc_symbols.append(symbol)\n",
    "            classification_titles.append(title)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'CPC Symbol': cpc_symbols,\n",
    "        'Classification Title': classification_titles\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = dict_to_dataframe(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv(\"classification_df.csv\" , sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep working to make a loop that gets the entire dataset eventually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
